{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "hMqWDc_m6rUC"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2020 Google LLC. Double-click here for license information.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4f3CKqFUqL2-"
      },
      "source": [
        "# Validation Sets and Test Sets\n",
        "\n",
        "The previous Colab exercises evaluated the trained model against the training set, which does not provide a strong signal about the quality of your model. In this Colab, you'll experiment with validation sets and test sets.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3spZH_kNkWWX"
      },
      "source": [
        "## Learning objectives\n",
        "\n",
        "After doing this Colab, you'll know how to do the following:\n",
        "\n",
        "  * Split a [training set](https://developers.google.com/machine-learning/glossary/#training_set) into a smaller training set and a [validation set](https://developers.google.com/machine-learning/glossary/#validation_set).\n",
        "  * Analyze deltas between training set and validation set results.\n",
        "  * Test the trained model with a [test set](https://developers.google.com/machine-learning/glossary/#test_set) to determine whether your trained model is [overfitting](https://developers.google.com/machine-learning/glossary/#overfitting).\n",
        "  * Detect and fix a common training problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gV82DJO3kWpk"
      },
      "source": [
        "## The dataset\n",
        "\n",
        "As in the previous exercise, this exercise uses the [California Housing dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) to predict the `median_house_value` at the city block level.  Like many \"famous\" datasets, the California Housing Dataset actually consists of two separate datasets, each living in separate .csv files:\n",
        "\n",
        "* The training set is in `california_housing_train.csv`.\n",
        "* The test set is in `california_housing_test.csv`.\n",
        "\n",
        "You'll create the validation set by dividing the downloaded training set into two parts:\n",
        "\n",
        "* a smaller training set  \n",
        "* a validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u84mXopntPFZ"
      },
      "source": [
        "## Use the right version of TensorFlow\n",
        "\n",
        "The following hidden code cell ensures that the Colab will run on TensorFlow 2.X."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "FBhNIdUatOU6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorflow_version` not found.\n"
          ]
        }
      ],
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S8gm6BpqRRuh"
      },
      "source": [
        "## Import relevant modules\n",
        "\n",
        "As before, this first code cell imports the necessary modules and sets a few display options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "9D8GgUovHbG0"
      },
      "outputs": [],
      "source": [
        "#@title Import modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xjvrrClQeAJu"
      },
      "source": [
        "## Load the datasets from the internet\n",
        "\n",
        "The following code cell loads the separate .csv files and creates the following two pandas DataFrames:\n",
        "\n",
        "* `train_df`, which contains the training set.\n",
        "* `test_df`, which contains the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zUnTc_wfd_o3"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P_KBdj2M_yjM"
      },
      "source": [
        "## Scale the label values\n",
        "\n",
        "The following code cell scales the `median_house_value`. \n",
        "See the previous Colab exercise for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3hc7QQhaAFXD"
      },
      "outputs": [],
      "source": [
        "scale_factor = 1000.0\n",
        "\n",
        "# Scale the training set's label.\n",
        "train_df[\"median_house_value\"] /= scale_factor \n",
        "\n",
        "# Scale the test set's label\n",
        "test_df[\"median_house_value\"] /= scale_factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FhessIIV8VPc"
      },
      "source": [
        "## Load the functions that build and train a model\n",
        "\n",
        "The following code cell defines two functions:\n",
        "\n",
        "  * `build_model`, which defines the model's topography.\n",
        "  * `train_model`, which will ultimately train the model, outputting not only the loss value for the training set but also the loss value for the validation set. \n",
        "\n",
        "Since you don't need to understand model building code right now, we've hidden this code cell. As always, you must run hidden code cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "bvonhK857msj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined the build_model and train_model functions.\n"
          ]
        }
      ],
      "source": [
        "#@title Define the functions that build and train a model\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Compile the model topography into code that TensorFlow can efficiently\n",
        "  # execute. Configure training to minimize the model's mean squared error. \n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model               \n",
        "\n",
        "\n",
        "def train_model(model, df, feature, label, my_epochs, \n",
        "                my_batch_size=None, my_validation_split=0.1):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  history = model.fit(x=df[feature],\n",
        "                      y=df[label],\n",
        "                      batch_size=my_batch_size,\n",
        "                      epochs=my_epochs,\n",
        "                      validation_split=my_validation_split)\n",
        "\n",
        "  # Gather the model's trained weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the \n",
        "  # rest of history.\n",
        "  epochs = history.epoch\n",
        "  \n",
        "  # Isolate the root mean squared error for each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history   \n",
        "\n",
        "print(\"Defined the build_model and train_model functions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8gRu4Ri0D8tH"
      },
      "source": [
        "## Define plotting functions\n",
        "\n",
        "The `plot_the_loss_curve` function plots loss vs. epochs for both the training set and the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "QA7hsqPZDvVM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ]
        }
      ],
      "source": [
        "#@title Define the plotting function\n",
        "\n",
        "def plot_the_loss_curve(epochs, mae_training, mae_validation):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], mae_training[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], mae_validation[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  \n",
        "  # We're not going to plot the first epoch, since the loss on the first epoch\n",
        "  # is often substantially greater than the loss for other epochs.\n",
        "  merged_mae_lists = mae_training[1:] + mae_validation[1:]\n",
        "  highest_loss = max(merged_mae_lists)\n",
        "  lowest_loss = min(merged_mae_lists)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "   \n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jipBqEQXlsN8"
      },
      "source": [
        "## Task 1: Experiment with the validation split\n",
        "\n",
        "In the following code cell, you'll see a variable named `validation_split`, which we've initialized at 0.2.  The `validation_split` variable specifies the proportion of the original training set that will serve as the validation set. The original training set contains 17,000 examples. Therefore, a `validation_split` of 0.2 means that:\n",
        "\n",
        "* 17,000 * 0.2 ~= 3,400 examples will become the validation set.\n",
        "* 17,000 * 0.8 ~= 13,600 examples will become the new training set.\n",
        "\n",
        "The following code builds a model, trains it on the training set, and evaluates the built model on both:\n",
        "\n",
        "* The training set.\n",
        "* And the validation set.\n",
        "\n",
        "If the data in the training set is similar to the data in the validation set, then the two loss curves and the final loss values should be almost identical. However, the loss curves and final loss values are **not** almost identical. Hmm, that's odd.  \n",
        "\n",
        "Experiment with two or three different values of `validation_split`.  Do different values of `validation_split` fix the problem? \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "knP23Taoa00a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 47124.3359 - root_mean_squared_error: 217.0814 - val_loss: 38075.3711 - val_root_mean_squared_error: 195.1291\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 32072.4961 - root_mean_squared_error: 179.0880 - val_loss: 25120.8203 - val_root_mean_squared_error: 158.4955\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 20768.7012 - root_mean_squared_error: 144.1135 - val_loss: 15738.7305 - val_root_mean_squared_error: 125.4541\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 12935.5918 - root_mean_squared_error: 113.7347 - val_loss: 9760.0898 - val_root_mean_squared_error: 98.7932\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 8572.4795 - root_mean_squared_error: 92.5877 - val_loss: 7105.7568 - val_root_mean_squared_error: 84.2957\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 7212.9932 - root_mean_squared_error: 84.9293 - val_loss: 6797.2070 - val_root_mean_squared_error: 82.4452\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 7157.8877 - root_mean_squared_error: 84.6043 - val_loss: 6801.4312 - val_root_mean_squared_error: 82.4708\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 7155.0269 - root_mean_squared_error: 84.5874 - val_loss: 6807.0166 - val_root_mean_squared_error: 82.5046\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 7152.8643 - root_mean_squared_error: 84.5746 - val_loss: 6809.3511 - val_root_mean_squared_error: 82.5188\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 7150.0269 - root_mean_squared_error: 84.5578 - val_loss: 6815.4453 - val_root_mean_squared_error: 82.5557\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 7150.0815 - root_mean_squared_error: 84.5582 - val_loss: 6816.4980 - val_root_mean_squared_error: 82.5621\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 7148.7100 - root_mean_squared_error: 84.5500 - val_loss: 6821.8071 - val_root_mean_squared_error: 82.5942\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 7148.7397 - root_mean_squared_error: 84.5502 - val_loss: 6821.9272 - val_root_mean_squared_error: 82.5950\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 7147.1514 - root_mean_squared_error: 84.5408 - val_loss: 6824.0479 - val_root_mean_squared_error: 82.6078\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 7147.7300 - root_mean_squared_error: 84.5443 - val_loss: 6826.9424 - val_root_mean_squared_error: 82.6253\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 7148.1177 - root_mean_squared_error: 84.5465 - val_loss: 6827.9521 - val_root_mean_squared_error: 82.6314\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 7145.7930 - root_mean_squared_error: 84.5328 - val_loss: 6828.8086 - val_root_mean_squared_error: 82.6366\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 7147.2690 - root_mean_squared_error: 84.5415 - val_loss: 6831.8213 - val_root_mean_squared_error: 82.6548\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 7147.5073 - root_mean_squared_error: 84.5429 - val_loss: 6832.5767 - val_root_mean_squared_error: 82.6594\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 7146.5498 - root_mean_squared_error: 84.5373 - val_loss: 6833.9365 - val_root_mean_squared_error: 82.6676\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 7146.9365 - root_mean_squared_error: 84.5396 - val_loss: 6833.4775 - val_root_mean_squared_error: 82.6648\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 7146.3945 - root_mean_squared_error: 84.5364 - val_loss: 6833.6807 - val_root_mean_squared_error: 82.6661\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 7146.4966 - root_mean_squared_error: 84.5370 - val_loss: 6834.2666 - val_root_mean_squared_error: 82.6696\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 7145.5796 - root_mean_squared_error: 84.5315 - val_loss: 6838.4106 - val_root_mean_squared_error: 82.6947\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 7146.1865 - root_mean_squared_error: 84.5351 - val_loss: 6836.2847 - val_root_mean_squared_error: 82.6818\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 7145.6763 - root_mean_squared_error: 84.5321 - val_loss: 6840.0317 - val_root_mean_squared_error: 82.7045\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 7143.3921 - root_mean_squared_error: 84.5186 - val_loss: 6841.6084 - val_root_mean_squared_error: 82.7140\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 7140.6831 - root_mean_squared_error: 84.5026 - val_loss: 6842.2612 - val_root_mean_squared_error: 82.7180\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 7146.2676 - root_mean_squared_error: 84.5356 - val_loss: 6839.5122 - val_root_mean_squared_error: 82.7013\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 7142.7700 - root_mean_squared_error: 84.5149 - val_loss: 6845.7554 - val_root_mean_squared_error: 82.7391\n",
            "96.64277648925781\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3qUlEQVR4nO3de1xU1fo/8M8MoKBcFQEF5CbiJTMENDOttKOSKXYqxTxKWlZkF+uc0qyOXc7Pk5XHLEuLQyoWmpgmfjXyhsoxlBGGm4AM9+EOgoDIdWb9/gC2DDPDADKzmeF5v17rxczas/d+NgPzzN5r7bUEABgIIYSQToR8B0AIIWTgoeRACCFECSUHQgghSig5EEIIUULJgRBCiBJjvgO4F+Xl5cjPz+c7DEII0SsuLi6ws7Pr9jV6nRzy8/Ph5+fHdxiEEKJXRCKRxtfQZSVCCCFKKDkQQghRQsmBEEKIEq21OYSGhuLJJ59EeXk5pkyZAgCYOnUq9uzZA1NTU7S2tuLVV1/lrn3t3LkTTzzxBO7cuYPnn38eYrFYW6ERQnrJxsYGGzZsgKurKwQCAd/hkB5gjCEvLw9fffUVqqur+7YNbZTZs2czb29vlpKSwtX98ccfbOHChQwA8/f3Z9HR0dzjU6dOMQBsxowZ7MqVKz3ah0gk0krsVKhQUSwff/wxW7x4MTMyMuI9Fio9K0ZGRmzJkiXs448/VlrWk89OrV1WiomJQVVVlUIdYwyWlpYAACsrKxQXFwMAAgICEBYWBgC4evUqrK2t4eDgoK3QCCG95OrqilOnTkEmk/EdCukhmUyGkydPwtXVtU/r67Qr64YNG/DHH3/gyy+/hFAoxEMPPQQAcHR0hFQq5V5XWFgIR0dHlJaWKm1j3bp1eOmllwAAtra2ugmckEFOIBBQYtBDMpmsz5cBddogHRwcjLfeegtjx47FW2+9hdDQ0F5vIyQkBH5+fvDz80NlZWWf4nDw9MCiDcEwNR/ep/UJIcTQ6TQ5BAUF4ejRowCAiIgITJ8+HQBQVFQEZ2dn7nVOTk4oKirSWhwjHUdj7gurYefmorV9EEL6z4gRIyAWiyEWi1FSUoLCwkLuuYmJSbfr+vj4YOfOnRr3cfny5X6J9ZFHHsGJEyf6ZVt80mlyKC4uxiOPPAIAmDt3LiQSCQAgMjISq1evBgDMmDEDNTU1Ki8p9ZeK/LZLWKNcKTkQog+qqqrg7e0Nb29v7NmzBzt27OCet7S0wMjISO268fHxePPNNzXuY9asWf0Zst7TWnIIDw9HbGwsvLy8IJVKsXbtWqxbtw7bt29HYmIitm7dyrUdnDp1Cjk5OcjKykJISAheffVVbYUFALgpLYKstRV2rmO1uh9CiPbs3bsXu3fvxpUrV/D555/Dz88Pf/75JxISEnD58mWMHz8egOI3+S1btiA0NBTR0dHIzs7G66+/zm2vrq6Oe310dDQiIiKQnp6On376iXuNv78/0tPTce3aNezcubNXZwiBgYFITk5GSkoKPvvsMwCAUCjE3r17kZKSguTkZGzYsAEA8Prrr+P69etISkrCwYMH7+n31Fdaa5B+7rnnVNb7+vqqrH/ttde0FYoSWWsrqgqLMYqSAyG9FvDuBoyZ4Nmv2yzOkOD451/1ej0nJyc89NBDkMvlsLCwwOzZsyGTyTBv3jxs3boVzzzzjNI6EyZMwGOPPQYLCwvcuHEDu3fvRmtrq8JrvL29MXnyZBQXF+Py5cuYNWsWrl27hu+//x5z5sxBXl4ewsPDexzn6NGjsW3bNvj4+KC6uhqnT59GQEAApFIpHB0duXvBrKysAACbNm2Cm5sbmpubuTpdG7R3SJfnFVCbAyF6LiIiAnK5HEDbB2tERARSUlKwY8cOTJ48WeU6J0+eRHNzM27evIny8nLY29srvSYuLg5FRUVgjCExMRGurq6YMGECcnJykJeXBwC9+kbv5+eHCxcuoLKyEjKZDD///DPmzJmDnJwcuLu74+uvv8aCBQtQW1sLAEhOTsbPP/+MlStXKiUuXdHrUVnvRUVeAcbP9INAKARr/+MihGjWl2/42lJfX889/vTTTxEdHY2//vWvcHFxwYULF1Su09TUxD2WyWQwNlb+GOzJa/rDrVu3MHXqVCxYsACvvPIKli1bhhdeeAGLFi3CnDlzsHjxYrz//vuYMmWKzrsSD+Izh3yYDB0Ka4fuxzQnhOgHKysrrpfj888/3+/bv3HjBtzd3eHi0nbFYfny5T1eNy4uDo888ghGjhwJoVCIFStW4OLFi9zzo0eP4oMPPsC0adMgEAjg7OyMCxcuYOPGjbCysoK5uXm/H48mg/rMAQDsXF1QXay9nlGEEN34/PPPsX//fnzwwQc4efJkv2+/sbERr776KqKiolBfX9/tnAjz5s1TuLH32WefxaZNmxAdHQ2BQICTJ08iMjIS999/P/bu3QuhsO17+nvvvQcjIyP89NNPsLKygkAgwNdff42ampp+P56e4H0MkL6WexlbyXykDdueEssefu5Z3o+DCpWBXsLCwniPYSCU4cOHc4+//fZbtmHDBt5j6st7x+vYSgPd7ZvVaKito0ZpQkiPrVu3DmKxGNevX4eVlRW+//57vkPSmkF7WQlo67FE3VkJIT311Vdf4auvvuI7DJ0YtGcOAFCRX0A3whFCiAqDOznkFcDawR5DzEz5DoUQQgaUQZ0cytt7LI1yobMHQgjpbFAnh4q8fACgdgdCCOlicCeH/ELI5XJqdyBkgDt//jzmz5+vUPfmm2/iu+++U7tOdHQ0fHx8ALQNmaFqjKItW7bg73//e7f7DggIwMSJE7nnH3/8MebNm9eb8FUa6EN7D+rk0NrUhFslZXTmQMgAd/DgQQQGBirUBQYG9nh8o0WLFvX5RrKlS5di0qRJ3PMtW7bg3LlzfdqWPhnUyQFou7REyYGQge3IkSNYtGgRN7GPi4sLxowZg5iYGHz33XcQiURITU3FRx99pHL93NxcjBw5EgCwefNm3LhxAzExMfDy8uJe8+KLLyIuLg6JiYk4cuQIzMzMMHPmTCxZsgRffPEFxGIx3N3dsXfvXjz99NMA2ualSUhIQHJyMkJDQzFkyBBufx999BHi4+ORnJyssB9NBsrQ3oP6PgegrVHab+kivsMgRG/s2PEipj7g3q/bTErMwVtv/Vft8urqasTFxcHf3x+RkZEIDAzE4cOHAQDvv/8+qqurIRQKce7cOUyZMgUpKSkqtzNt2jQEBgbigQcegLGxMRISEhAfHw8AOHr0KP7737YYPv30U7zwwgvYtWsXIiMj8X//93/49ddfFbY1dOhQ7Nu3D/PmzYNEIsH+/fsRHBzMzTpXWVkJHx8fBAcH4x//+AfWrVun8fcwkIb2pjOHvAKYDh8Oy1G2fIdCCOlG50tLnS8pLVu2DPHx8RCLxZg8ebLCJaCuZs+ejWPHjqGhoQF1dXWIjIzklt133324dOkSkpOTsXLlSrVDfnfw8vJCbm4uN6Pl/v37MWfOHG55x5TI8fHxcHV17dExDqShvenMoaM7q+tY1FZU8hwNIQNfd9/wten48ePc9KDDhg1DQkICXF1d8Y9//AN+fn64desW9u7dC1PTvt23tG/fPixduhTJyckICgrCo48+ek/xdgz73R9DfvMxtDedOXQanZUQMnDV19cjOjoaP/74I3fWYGlpifr6etTU1MDOzg7+/v7dbuPSpUtYunQpTE1NYW5ujsWLF3PLLCwsUFJSAmNjY6xcuZKrr6urg4WFhdK2bty4AVdXV3h4eAAAVq1ahYsXL97TMQ6kob0H/ZlDTVk5mhsaMcqNGqUJGegOHjyI3377jbu8lJycDLFYjIyMDEilUly+fLnb9cViMX755RckJSWhvLxcYdjtDz/8EFevXkVFRQWuXr3KJYRDhw4hJCQEb7zxhsK0o01NTVizZg0iIiJgbGwMkUiEPXv29Op4BvrQ3rwPKdvXci9Ddncub0fsZy9+t53346FCZaAWGrJbfwsN2X0PKmh0VkIIUUDJAW2N0iPGjIZRex9qQggZ7Cg5oO1GOKGREWydHfkOhZABiTEGIyMjvsMgvWRkZATGWJ/WpeQAoDy3ozurC8+REDIw5eXlYdGiRZQg9IiRkREWLVqEvLy8Pq0/6HsrAW2T/gCAHfVYIkSlr776Chs2bMDTTz8NgUDAdzikBxhjyMvL6/PMdZQcADTV30FNeQU1ShOiRnV1NbZs2cJ3GESH6LJSu4q8AroRjhBC2lFyaFeRL6UzB0IIaUfJoV15Xj6GW1thuLUV36EQQgjvKDm0q6AeS4QQwqHk0K6cG4CPLi0RQgglh3bVxSVobWnBKFdnvkMhhBDeaS05hIaGoqysTGlGptdeew3p6elITU3Ftm3buPpNmzZBIpEgIyNDaSJxXZDLZKgsKKTLSoQQAi3e57Bv3z7s2rULYWFhXN2jjz6KgIAATJ06Fc3NzRg1ahQAYOLEiQgMDMTkyZMxZswYnD17FuPHj4dcLtdWeCrRAHyEENKm2zMHoVCIL774ok8bjomJQVVVlUJdcHAwPvvsMzQ3NwMAKioqAAABAQE4dOgQmpubkZeXh6ysLEyfPr1P+70XFXn5sB3rBCENEUAIGeS6TQ5yuRwPP/xwv+1s/PjxmD17Nq5cuYILFy7A19cXAODo6Kgw4UVhYSEcHVUPgrdu3TqIRCKIRCLY2vbvvM/leQUwNjGBzZjR/bpdQgjRNxovK4nFYhw/fhwRERGor6/n6o8dO9b7nRkbY8SIEXjwwQfh5+eHw4cPw93dvVfbCAkJQUhICAAozOLUHzq6s9q5jsVNaWG/bpsQQvSJxuRgamqKmzdvYu7cuVwdY6xPyaGwsBBHjx4F0PbBLpfLYWtri6KiIjg73+0l5OTkhKKiol5vv6dcXe3h7++DffvOoaGhiavvGIBvlNtYpMf8qbX9E0LIQKcxOaxdu7bfdvbbb7/hsccew4ULF+Dp6YkhQ4agsrISkZGRCA8Px3/+8x+MGTMGnp6eiIuL67f9djVtmge+/S4YV6/eQEJCNldff6sG9bdqaIwlQsigp7Erq6OjI44ePYqysjKUlZXhyJEjatsDOgsPD0dsbCy8vLwglUqxdu1a/Pjjj3B3d0dKSgoOHTqEoKAgAEBaWhoOHz6MtLQ0REVFYf369VrtqZSe3ta+MXGi8j0N1GOJEELadDvJ9OnTp9nzzz/PjIyMmJGREQsKCmKnT5/mfdJs9HCSbFXFxMSYNTUfY//61yqlZcs/fZ9tOX+C92OjQoUKFW2Vnnx2ajxzGDVqFPbt2weZTAaZTIb9+/dz9yfoq5aWVmRllWDCRCelZRV5BbAcZYuhw4fxEBkhhAwMGpPDzZs3sXLlSgiFQgiFQqxcuRI3b97URWxalZ4uxaRJypePuClDXejSEiFk8NKYHNauXYtly5ahtLQUJSUleOaZZ7BmzRpdxKZVGemFGDduNExMFNvkK/LyAdCUoYSQwa3b3kpCoRBbt25FQECAruLRmfR0KYyNjTBu3GiugRoAKqVFkMtkNMYSIWRQ03iHtIuLC0xMTHQVj86kpanusSRraUFVUQkN3U0IGdQ03ueQk5ODy5cvIzIyUuEO6R07dmg1MG27caPtDuiJKhqly/PyqTsrIWRQ05gcsrOzkZ2dDaFQCAsLC13EpBN37jQhL68ME1U0SlfkSzHOzwcCgQCMMR6iI4QQfmlscxg/fjz+9re/6SoenUpPL1R55lCRW4AhZqawsrfDrdIyHiIjhBB+Ddo2BwDISJfCy8sJAoFAob6ceiwRQga5QdvmALT1WBo2bChcXOyQl3f3DKEi7+69Dpmx/TvyKyGE6INB2+YAdO6x5KSQHGorKtFYX0+N0oSQQUtjcvjkk0+U6owMZKa0zgPw/f57vMKyirwC6s5KCBm01LY5xMTEcI87zwMNQKvDaetSdfVtlJVVY9IkdaOz0o1whJDBSW1yGD58OPf4vvvuU1jWtQFXn6WnF2KCiqG7y/MKYD3aHsZDh/IQFSGE8Ettcujcv79rX39D6vufkS5VPa9Dbj6EQiFGuSh3dSWEEEOnts3B2toaS5cuhVAohLW1NZ566ikAbWcNVlZWOgtQ29LSpLCxMYe9vTXKym5x9eUdPZZcXVCSma1mbUIIMUxqk8PFixexZMkS7vHixYu5ZZcuXdJ+ZDrSuVG6c3KoLGirp0ZpQshgpDY59Ofc0QNZR3KYNMkZFy6kcPXNDY24VVpG3VkJIYOSxvkcDF1xcRVqa++obHcozyuAHfVYIoQMQoM+OQBtZw+qeixV5BVglItyPSGEGDpKDlA/AF95bj7MLC1gPtKGh6gIIYQ/atscOnonqXPs2LF+D4Yv6WkFeP75ebC0HIba2jtcfccYS3auLrh9s5qv8AghROfUJoeO3kl2dnZ46KGHcP78eQDAY489hj///NOwkkOnHktXr97g6jtGZx3lOhY58Yl8hEYIIbzQ2Fvpjz/+wKRJk1BaWgoAcHBwwL59+3QSnK6kp7fNCjdpkmJyuFVShpbGJmqUJoQMOhrbHJydnbnEAABlZWUYO9awunfm5pahsbFZqccSYwwVBVLqzkoIGXQ0jsp67tw5REVF4eDBgwCA5cuX4+zZs1oPTJfkcjkyM4vU9lgaM34cD1ERQgh/NCaH119/HUuXLsWcOXMAAD/88AN+++03bcelc+nphfD1VU4CFXkFuG/uHBgZG0PW2spDZIQQonsakwMAJCQkoK6uDufOnYOZmRnMzc1x+/ZtbcemU+lpBXj22VkwNR2CxsZmrr40OxdGxsYY5eaCUgmNsUQIGRw0tjm8+OKLOHLkCL7//nsAgKOjo8GeOQiFQnh5OSrUl7QnhNHj3PkIixBCeKExOaxfvx6zZs1CbW0tACArKwt2dnZaD0zXOndn7awiNx+yllY4eHrwERYhhPBCY3JoampCS0sL99zIyMig5nPokJlZBJlMppQcZK2tKM/Lx2hKDoSQQURjcrh48SLee+89mJmZ4fHHH0dERAROnDihi9h0qrm5FTk5ZZigYhiNUkk2JQdCyKCiMTls3LgRFRUVSElJwcsvv4xTp07hgw8+0Ljh0NBQlJWVISUlRWnZ22+/DcYYRo4cydXt3LkTEokESUlJ8Pb27uVh9I+0tAKVo7OWSHIwwnE0hg4fxkNUhBDCD6auCIVClp6ernZ5d2X27NnM29ubpaSkKNQ7OTmxqKgolpeXx0aOHMkAMH9/f3bq1CkGgM2YMYNduXKlR/sQiUR9ik1d+fe/g1hj01FmZCRUqJ/0yMNse0osc5l6X7/ujwoVKlT4KD357Oz2zEEul+PGjRtwdu79sNUxMTGoqqpSqt+xYwfeffddhXaLgIAAhIWFAQCuXr0Ka2trODg49Hqf9yo9XYohQ0zg4TFaob40q73HEl1aIoQMEhrvc7CxscH169cRFxeH+vp6rj4gIKDXO1uyZAmKioqQnJysUO/o6AipVMo9LywshKOjo8KwHR3WrVuHl156CQBga2vb6xi607nHUmZmEVdfXVyKxvp6Sg6EkEFDY3L48MMP+2VHZmZm2Lx5M+bPn39P2wkJCUFISAgAQCQS9UdonIyMtgH4Jk50wvHjd+sZYyjNyqHurISQQUNjcrh06VK/7MjDwwNubm5ISkoCADg5OSEhIQHTp09HUVGRwqUrJycnFBUVqduU1tTVNaCwsFLlGEslkmzcP+9RncdECCF80NhbacaMGYiLi0NdXR2amprQ2tqKmpqaXu8oNTUV9vb2cHNzg5ubGwoLCzFt2jSUlZUhMjISq1ev5vZXU1Oj8pKSLqSlSVX2WCqVZGO4jTUsbEeqWIsQQgyLxuSwa9curFixAhKJBGZmZnjxxRfx7bffatxweHg4YmNj4eXlBalUys0PocqpU6eQk5ODrKwshISE4NVXX+3dUfSjjHQpJk50gkAgUKgvkeQAoEZpQsjg0aMuT0lJSVxdQkIC712xOsfWn+XllxcyOTvBnJ1HKdQPt7Zi21Ni2SOrV/B+3FSoUKFyL6Unn50a2xzu3LkDExMTJCYmYtu2bSgpKYFQqPGEQ291zAo3caITpNIKrr7+Vg1qKyrh4EkD8BFCDJ/GT/lVq1bByMgIr732Gurr6+Hs7Iynn35aF7HxQt0AfEBbozRdViKEDAYazxwKCgoAAI2Njfjkk0+0HhDfKipqUFlZqzY5zFr+NARCIZhczkN0hBCiGxqTQ05OjspRWD08DPcbdHq6VPUAfFk5MDEdipHOjqjMl6pYkxBCDIPG5ODr68s9NjU1xbPPPosRI0ZoNSi+ZaRL8dRfH1KqL8m8O4wGJQdCiCHT2OZQVVXFleLiYuzcuROLFi3SRWy8SU8vhK2tJWxtLRXqy3JyIZfLaVY4QojB03jm0Hn4bKFQCF9fXxgb92jqab3VuVE6JuY6V9/S2ISbBYU0jAYhxOBp/JTfvn0797i1tRV5eXlYtmyZVoPim7rkAFCPJULI4KAxOcydO1cXcQwoUmklbt9uwEQ1jdL3zZ0D46FD0drUxEN0hBCifRqTw1tvvdXt8h07dvRbMAMFYwwZGYWYOGms0rISSTaERkawd3dBUXomD9ERQoj2aWyQ9vX1RXBwMBwdHeHo6IhXXnkF06ZNg4WFBSwsLHQRIy/S0wtVnjmUSDp6LI3TdUiEEKIzGs8cnJycMG3aNNy+fRsA8NFHH+HkyZNYtWqV1oPjU0a6FKtWPQZzczPcvt3A1VcWFKKlsYnaHQghBk3jmYO9vT2am5u5583NzbC3t9dqUANBR6P0hAmKZw9MLkdpTi5G0xhLhBADpvHMISwsDHFxcTh27BgEAgECAgKwb98+HYTGr84D8F27JlFYVirJwfiZfnyERQghOqExOWzduhW///47Zs+eDcYY1qxZg8TERB2Exq/s7BI0N7eonfjHL+AJDLOyxJ2aWh6iI4QQ7VJ7WcnMzIy72U0sFiMqKgpGRkZwc3PTWXB8am2VQSIpwcRJqgfgA0A3wxFCDJba5BAVFQVXV1cAbYPsxcbGwt3dHevXr8e///1vXcXHq/R01VOG3u2xRMmBEGKY1CYHGxsbZGVlAQCCgoJw8OBBvPHGG/D39zf4sZU6ZKRL4eHhgCFDFK++1VZUov5WDSUHQojBUpscOg/TPXfuXJw5cwYA0NLSAvkgmcsgPb0QRkZG8PQco7SsNCuHkgMhxGCpbZBOTk7GF198gaKiIowbNw6nT58GAFhZWeksOL6lpbVNdDRxojOuXy9QWFYiyYbvYn8+wiKEEK1Te+awbt06VFZWwtXVFfPnz0dDQ9uNYJMmTcKXX36pswD5dONGEeRyudp2B1Pz4bAZ7cBDZIQQol1qzxwaGxuxbds2pfrY2FjExsZqNaiBorGxGXl55Sp7LJVm3u2xVF1SquvQCCFEqzTeIT3Yqe2xlEU9lgghhouSgwYZ6YXw8nKEUKj4q2qqv4Oq4hIaRoMQYpAoOWiQnJwLU9Mh8PJyVFpWKsmhG+EIIQZJ4/AZnp6eeOedd+Di4qIwPei8efO0GthAER/fdvnIx2ccNxhfhxJJNsY/NB1CYyPIW2V8hEcIIVqhMTlERERgz549CAkJgUw2+D4AMzIKUV/fCB8fD/z0U7TCshJJNoxNTGDn6oLSrByeIiSEkP6nMTm0trZiz549uohlQJLL5UhMzME0H+XJfUo7NUpTciCEGBKNbQ4nTpxAcHAwHBwcYGNjw5XBJCE+G97e7kqN0uU5+ZC1tMJhHDVKE0IMi8Yzh6CgIADAO++8w9UxxuDhMXgaYuPjs/D6G4sxfvwYZGQUcvWy1laU5+VTd1ZCiMHRmBzc3elbcXx82wCEPj7jFJID0Da3w9j77+MjLEII0RqNyQEAJk+ejEmTJsHU1JSrO3DggNaCGmgyMgpx504TfHzG4eefLygsK5HkwPuJ+Rg6bBia7tzhJ0BCCOlnGtsc/vnPf+Kbb77BN998g8ceewyff/45lixZonHDoaGhKCsrQ0pKClf3+eefIz09HUlJSTh69KjCIH6bNm2CRCJBRkYG5s+f38fD0Q6ZrKNRWvnyUUejtP24wTEJEiFkcNCYHJ555hnMmzcPpaWlWLt2LaZOndqjkVn37duHhQsXKtSdOXMG9913H6ZOnYrMzEy89957AICJEyciMDAQkydPxsKFC/Hdd98pNf7yLSE+C97e7hAIBAr1NPEPIcQQafwEbmhoAGMMra2tsLCwQHl5OZydlcca6iomJgZVVVUKdWfOnOHulbhy5QqcnJwAAAEBATh06BCam5uRl5eHrKwsTJ8+vS/HozXx8dmwsBiG8eMV75SuLi5FY309JQdCiEHRmByuXbsGKysrhISEID4+HgkJCf0yKuvatWvx+++/AwAcHR0hld69+7iwsBCOjsrDVQBtQ4mLRCKIRCLY2trecxw9dbdRWjEJMMZo4h9CiMHR2CC9fv16AMD333+PqKgoWFpaKrQj9MXmzZvR2tqKn3/+udfrhoSEICQkBAAgEonuKY7eSE+Xco3S4eEXFZaVSLJx/7xHdRYLIYRoW48u7K9cuRIffvgh8vPzcevWLfj5+fV5h0FBQXjyySexcuVKrq6oqEjhUpWTkxOKior6vA9tkMnkSErKVX2ntCQHw22sYTFyBA+REUJI/9OYHL777jvMnDkTK1asAADU1dXh22+/7dPOFixYgHfffRdLlizhZpYDgMjISAQGBmLIkCFwdXWFp6cn4uLi+rQPbdLYKD2eLi0RQgyDxuQwY8YMvPbaa2hsbAQA3Lp1C0OGDNG44fDwcMTGxsLLywtSqRRr167Frl27YGFhgTNnzkAsFmP37t0AgLS0NBw+fBhpaWmIiorC+vXrIZfL7/HQ+l98fBYsLYfB03OMQn2p5O6scIQQYgg0tjm0tLRAKBSCMQYAsLW17dEH93PPPadU9+OPP6p9/datW7F161aN2+VTx/Ddvr7jkJl597JX/a0a1FZUUqM0IcRgaDxz+Prrr3Hs2DHY2dnhX//6F/73v/8N+A9xbUlLK0BDQ1ujdFclkmwagI8QYjA0njmEh4cjPj4e8+bNg0AgwNKlS5GRkaGL2Aacbhuls3Iw89mnIBAKwQbgJTFCCOkNtcmh87Dc5eXlOHjwoMKy6upq7UY2QCXEZ+Nvqx6DQCDgLrUBbWcOQ8xMMdJpDCoLCrvZAiGEDHxqk0NlZSUKCwvR2toKAAo9dAbbkN2dxcdn4dX1i+DpOUah3aEk8+4wGpQcCCH6Tm2bw9dff43q6mpERUUhKCgI7u7uXBmsiQFQHL67s7KcXMjlcmqUJoQYBLXJ4a233sIDDzyAiIgIrFq1CmKxGNu2bYOrq6sOwxt40tKkaGxsVhpGo6WxCTcLCqk7KyHEIGjsrXThwgW8++672LNnD9asWYPHH39cF3ENWK2tMrWN0iU0xhIhxECoTQ7Dhg3DihUr8Ntvv+HUqVMwNzeHj48P/vvf/+oyvgEpIT4b06Z5KN0pLU1Ng52bC4bbWPMTGCGE9BO1DdLl5eWQSCQ4dOgQJBIJGGPw9fWFr68vAODYsWM6C3KgiY/PQvCrT2DcuNGQSIq5+ixRAgDAw9cbyWei+QqPEELumdrkEBERAcYYvLy84OXlpbCMMTbokwPQ1ijdOTkUpmWg6c4dePhNo+RACNFrapPDmjVrdBmHXrl+vaC9UXocDh26xNXLW2XISUiCh683j9ERQsi9G1hzceqJ1lYZkpPzVM4pnS1KwGhPD5iPsFGxJiGE6AdKDn2UEJ+lslE6u73dwZ3OHgghekxjclA1PHdPhuw2dPHx2bCyGg4PDweF+sK0G2isr8c4v2k8RUYIIfdOY3JQNV90f8whre/U3Sktl8mQm5AED0oOhBA9prZB2t7eHo6OjjAzM8MDDzzAXT6xtLTEsGHDdBbgQHX9egGamlrg4zMOv/wSo7AsW5SAJ99+DeYjbXD75uAcoJAQot/UJocFCxbg+eefh5OTE/7zn/9w9XV1ddi8ebNOghvIWlpa1TZKZ8V13O8wDUl/nNN1aIQQcs/UJoewsDCEhYXhr3/9K44eParLmPRGQnwWlgfOVqovyshE4+22dgdKDoQQfaSxzeHcuXPYvn07RCIRRCIRvvzyS1haWuoitgEvPj4L1tbm8PAYrVAvl8mQk5BI7Q6EEL2lMTmEhoairq4Oy5Ytw7Jly1BbW4u9e/fqIrYBr2NO6a4jtAJAdlwC7N1dYTFyhK7DIoSQe6YxOXh4eOCjjz5Cbm4ucnNz8cknn8DdneZKBoDU1HyuUborbpwlOnsghOghjcmhoaEBs2bN4p4/9NBDaGho0GpQ+qKlpRUpKXkqh+8uviFBQ91tSg6EEL2ktkG6Q3BwMPbv3w8rKysIBAJUVVUhKChIF7HphYT4bDy77GGlerlMhpz4RLoZjhCilzQmh6SkJDzwwAOwsLAA0NaVldwVH5+Fl15eCHd3B+TklCosyxYlYPKjD8NylC1qKyp5ipAQQnpP42UlS0tLbN++HefPn8f58+ept1IX6u6UBoDsa3fndyCEEH2iMTn8+OOP1FupG6mp+WhublHZY6koQ4KG2jpqdyCE6B2Nl5U8PDzwzDPPcM8/+eQTiMVirQalT5qbW5GSkq+yUZrJ5dTuQAjRS9RbqR90DN+tSta1BIxyHQtLu1E6jooQQvpOY3IIDg7Gt99+i9zcXOTl5WHXrl14+eWXdRGb3oiPz8aIERZwc7NXWpYdR+0OhBD9ozE5dPRWuv/++zFlyhT4+vpiypQpuohNb3TXKF2cmYU7tbV0aYkQolfUJgcLCwts2rQJ33zzDR5//HHU1dVh9erVyMrKwrJly3QZ44CXkpLX3iitvt2BGqUJIfpEbYP0gQMHUF1djdjYWKxbtw7vv/8+BAIBnnrqKSQlJekyxgHvbqO06naHbJEY9z02B1b2o1BTVqHj6AghpG+YqpKcnMw9FgqFrKysjA0dOlTla1WV0NBQVlZWxlJSUrg6Gxsbdvr0aZaZmclOnz7NrK2tuWU7d+5kEomEJSUlMW9v7x7tQyQS9TgebZfvv1/PKm+Gq1w2xsuTbU+JZdOeXMB7nFSoUKHSk89OtZeVWlpauMdyuRyFhYVoampS93Il+/btw8KFCxXqNm3ahHPnzmH8+PE4d+4cNm3aBADw9/eHp6cnPD098dJLL2H37t093s9A0dEo7eqq3ChdkpmFOzW1GOdLl5YIIfpBbXKYOnUqampqUFNTg9raWtx///3c45qaGo0bjomJQVVVlUJdQEAA9u/fDwDYv38/li5dytWHhYUBAK5evQpra2s4ODj09Zh4cbdRWvnSEmMMOfFieEyn5EAI0Q9qk4OxsTGsrKxgZWUFS0tLmJiYcI+trKz6tDN7e3uUlraNP1RaWgp7+7Zv2Y6OjpBKpdzrCgsL4ejoqHIb69at4yYesrW17VMc2tBdozTQNnWorbMTrB2UzywIIWSg0diVVZsYY71eJyQkBH5+fvDz80Nl5cAZzK65uRWpqQXw8VWTHER0vwMhRH/oNDmUlZVxl4scHBxQXl4OACgqKoKzszP3OicnJxQVFekytH5xTSTBjBleGDrURGlZqSQb9bdqMG66Dw+REUJI7+g0OURGRnJzQQQFBeH48eNc/erVqwEAM2bMQE1NDXf5SZ8cOXIZlpbDsHjxdKVljDFkXxPDw4/OHAgh+kErXaXCw8NZcXExa25uZlKplK1du5aNGDGCnT17lmVmZrIzZ84wGxsb7vW7du1iWVlZLDk5mfn4+PRbdyxdFqFQyKSF+9jxyA9VLn/4uWfZ9pRYZjPagfdYqVChMnhLDz87+Q9Uyweo0/LZZ0GsqfkYGzXKSmnZ6PEebHtKLPNd8gTvcVKhQmXwlnu6z4H0zYED0TAxMUZg4BylZaWSHNRX36JLS4SQAY+SQz+7fr0ACQnZWLX6MaVlXLsD3QxHCBngKDlowYGw8/D19cSkSWOVlmVfS8BIpzGwGaNfN/kRQgYXSg5acPDgJbS2yrBqlfLZQ1b7/A40hDchZCCj5KAF5eW3EBWVgOdWPgKhUPFXXJadi9tV1TSENyFkQKPkoCUHws7D2XkUHn30PoX6u/c7UHIghAxclBy05MSJONy6dRurVs9VWpYtSsCIMaMxwnE0D5ERQohmlBy0pLGxGUciLuPppx/C8OGmCsu4cZbo7IEQMkBRctCisLDzMDc3w1NPzVSoL8vORd3NKhpniRAyYFFy0KLLl9ORk1Oq8p6H1OhL8F74FzhOGM9DZIQQ0j1KDlrEGMNPB6Ixb95UjBkzQmHZyR27cbuqGs/9ewuMhwzhKUJCCFGNkoOWHTgQDaFQiJUrH1Wob6itxaEP/wWHce544s1X+AmOEELUoOSgZdnZJbh8OQ2rg+YpLcuMjcP/wiPwyOoV8Jzhy0N0hBCiGiUHHTgQFo3Jk8fC21t5fun/2/EtynPzEfivD2BqYc5DdIQQooySgw4cPhyDpqYWrFbRMN3S2ITw9z6Ghe1IPPXe2zxERwghyig56MCtW/U4cSIOK557BMbGRkrLpdfTceb7vfBd7I+pC5QvPxFCiK5RctCRA2HnYWdnjfnzVc/lcC5kP/KTr+OZD9+F5ShbHUdHCCGKKDnoSFRUAioqalQOpwEAcpkM4Zs/hvGQIVj+yfs6jo4QQhRRctCRlpZWHDp4CQEBM2BlNVzlayrzpTix/RtMePhBPLT8rzqOkBBC7qLkoENhYedhajoEzz47S+1r/vzlKDL+dwWL//46RrkqTxZECCG6QMlBh+Ljs5CWVqD20lKHX/75/9DS1ITntm6BUEUDNiGEaBslBx376UA0Zs+eDDc3e7Wvqa2oxJFPP8fYKZPw+ItBOoyOEELaUHLQsZ9/vgi5XI6//U35nofOkk+fx7UTv+Pxl9fA+b5JOoqOEELaUHLQMam0AtHRKSpHau3q2L//g7rKm3hu6z9hYjpUB9ERQkgbY74DGIwOhJ3Hvv1vYebMCYiNzVD7usa62zj4/qcIDt2F96OOou5mFRrq6tBYV9/+8zYabt9GY23bz4a622isuw1ZSwtYx0YYA2Os/WenOtytb6/q9JgB6PSYgXvM7m5EeR2F9Xuv83oK21Co79OG237cPRDlfXQhEAhUVfZh57j7HrQF0ekxuxtTxy4gUNqXQix9DKFj34ph9e19Ur/9/t1e59+Npk339q1Ruz2F96rT+9Ppf6Dz30/bQ8X/AVXvtUAogEAohEAguFuEQkAACATC9mWdYuv8fwt2d1vt9YwBLU1NaG1q6t2B94IASn8y+kMkEsHPz4/vMHrN3NwMJaVhuHgxFX9/OxQ3bhR2+/ppi+bD80E/mFlYwNR8OMwsLGBmaQ5Tc3OYWZhDaESN1oQMNudDw3Dyq919Wrcnn5105sCD27cbsP3LY/jgw+V44glfJCRk49DBizh0KAaFhZVKr084eRoJJ0+r3d7QYcNgatGeNCzMITRue1s7vqFAIOj0zUpFnUCg8I2145uqQADuK1lbnWI994228zpAn75hK347Fqh62LftdvkmrnBsHQ/UfI1UVd3bb9uCbn/PqmPofIbH1XX+DteXb+hdfneCrqcg3fwe+rL9e91kd++7QCBQ/T70dGdq/o46/i+A9t+PoFN91+WC9ld1/R/oeNplmVwua/v2L5ffPQNnDPL2553POLj/z/YYlP+P255Lr6u/6tAf6MyBR6NHj8CyZQ9jxXOPYPr0thnhYmKu49DBS4iI+B8qK2t5jpAQYoh68tlJyWGA8PAYjcDA2Qhc8QgmTx6L1lYZzp5NxKGDl3DsWCzq6hr4DpEjEAggFAq4n0KhUOn53dfeXafz+uq21fFNW9h+fbbrsp7Fp7gf7ptX+zLFeii8RiDo+nrluq776XpMqp93/9qexaL+99jdPtX/7qFRP59MKMXQua7z8Xb9e+hcpxjf3ba0zm1irPP1fhXbUPU7VvV30/k4uvvdq6tTjlWxvaLr8454Ov9fqfr/EgoFuHYtC5cvp3W7T3UoOeipKVNcsWLFHASumANXV3s0NjYjL69c6Q9ZyDVwKf/hd/1juvt6KPyxdV4fUP2B2fa444+WOrgRMhBs++wI3ntvf5/WpTYHPZWSkoeUlDxs3hyGBx/0wvLlszF6zEjum4dczlQ8vns9s6NOLu/8WA7GALlcrrCOXC4H0LNvYG3bk3fZvvLzzut0bK9jW13r2rarHNPdn12OsYdfZbvuU9W3NnXHqvpbner9Kx6n6hh6+tqex9Kzfaj6PSjH0bseW2qv96uh7rXq2nMU/waYwu+h899BWyw9+1Kjbhudf+edn3eOr/PvvWvcqo5N3fGq+qKl6nnX/6uu/7edlzU1tajcV3+h5DDAXblyA1eu3OA7DELIIMPLNYINGzYgNTUVKSkpCA8Px9ChQ+Hq6oorV65AIpHg0KFDMDEx4SM0Qggh4CE5jBkzBm+88QZ8fX0xZcoUGBkZITAwENu2bcOOHTvg6emJ6upqvPDCC7oOjRBCSDtezhyMjY1hZmYGIyMjDBs2DCUlJZg7dy6OHDkCANi/fz+WLl3KR2iEEELAQ3IoLi7Gl19+iYKCApSUlKCmpgbx8fG4desWZDIZAKCwsBCOjo4q11+3bh1EIhFEIhFsbWk6TUII0QadJwdra2sEBATAzc0NY8aMwfDhw7Fw4cIerx8SEgI/Pz/4+fmhslL5bmJCCCH3Tue9lR5//HHk5uZyH+xHjx7FrFmzYG1tDSMjI8hkMjg5OaGoqEjXoRFCCGmn8zOHgoICPPjggzAzMwMAzJs3D2lpaYiOjsYzzzwDAAgKCsLx48d1HRohhJB2Ok8OcXFxOHLkCBISEpCSkgKhUIgffvgBGzduxNtvvw2JRIKRI0ciNDRU16ERQghpp9fDZ5SXlyM/P1+hztbW1iDbIui49I+hHhsdl/7pemwuLi6ws7PTuB4zpCISiXiPgY6LjsuQj42OS/9KX46NRlEjhBCihJIDIYQQJQaXHH744Qe+Q9AKOi79Y6jHRself/pybHrdIE0IIUQ7DO7MgRBCyL2j5EAIIUSJwSSHBQsWICMjAxKJBBs3buQ7nH6Vm5uL5ORkiMViiEQivsPps9DQUJSVlSElJYWrs7GxwenTp5GZmYnTp0/D2tqavwD7SNVxbdmyBYWFhRCLxRCLxfD39+cxwr5xcnLC+fPncf36daSmpuKNN94AYBjvmbpj0/f3bejQobh69SoSExORmpqKjz76CAD6PF8O731w77UIhUKWlZXF3NzcmImJCUtMTGQTJ07kPa7+Krm5uWzkyJG8x3GvZfbs2czb25ulpKRwddu2bWMbN25kANjGjRvZZ599xnuc/XFcW7ZsYX//+995j+1eioODA/P29mYAmLm5Obtx4wabOHGiQbxn6o7NEN634cOHMwDM2NiYXblyhc2YMYP98ssvbPny5QwA2717N3vllVc0bscgzhymT5+OrKws5ObmoqWlBYcOHUJAQADfYZEuYmJiUFVVpVAXEBCA/fvbJknX13k8VB2XISgtLYVYLAYA3L59G+np6XB0dDSI90zdsRmC+vp6AICJiQlMTEzAGOvTfDkGkRwcHR0hlUq5593NB6GPGGM4ffo0rl27hnXr1vEdTr+yt7dHaWkpgLZ/WHt7e54j6j+vvfYakpKSEBoaqpeXXjpzcXGBt7c3rl69anDvWedjA/T/fRMKhRCLxSgvL8eZM2eQnZ3d4/lyFLaj7UDJvXv44Yfh4+MDf39/rF+/HrNnz+Y7JK1hjPEdQr/YvXs3PDw88MADD6CkpATbt2/nO6Q+Gz58OH799Vds2LABdXV1Ssv1+T3remyG8L7J5XJ4e3vDyckJ06dPx4QJE/q0HYNIDkVFRXB2duaeG9p8EMXFxQCAiooKHDt2DNOnT+c5ov5TVlYGBwcHAICDgwPKy8t5jqh/lJeXQy6XgzGGkJAQvX3PjI2N8euvv+Lnn3/GsWPHABjOe6bq2AzlfQOAmpoaREdHY+bMmdx8OUDPPx8NIjmIRCJ4enrC1dUVJiYmCAwMRGRkJN9h9Ythw4bB3Nycezx//nykpqbyHFX/iYyMRFBQEADDmsej48MTAJ566im9fc9CQ0ORnp6OHTt2cHWG8p6pOjZ9f99sbW1hZWUFADA1NcVf/vIXpKen93m+HN5b1/uj+Pv7sxs3brCsrCy2efNm3uPpr+Lm5sYSExNZYmIiS01N1etjCw8PZ8XFxay5uZlJpVK2du1aNmLECHb27FmWmZnJzpw5w2xsbHiPsz+OKywsjCUnJ7OkpCR2/Phx5uDgwHucvS2zZs1ijDGWlJTExGIxE4vFzN/f3yDeM3XHpu/v25QpU1hCQgJLSkpiKSkp7MMPP2RA2+fI1atXmUQiYYcPH2ZDhgzRuC0aPoMQQogSg7isRAghpH9RciCEEKKEkgMhhBAllBwIIYQooeRACCFECSUHQrrR2trKjdApFov7dcRfFxcXhZFcCRlIjPkOgJCBrKGhAd7e3nyHQYjO0ZkDIX2Qm5uLbdu2ITk5GVevXoWHhweAtrOBc+fOISkpCWfPnuWGdbGzs8PRo0eRmJiIxMREzJw5EwBgZGSEH374Aampqfjjjz9gamrK2zER0hXvd/VRoTJQS2trK3cHrVgsZsuWLWNA2xwbHXerr1q1ip04cYIBYJGRkWz16tUMAFuzZg07duwYA8AOHTrE3nzzTQa0zT9iaWnJXFxcWEtLC5s6dSoDwH755Re2cuVK3o+ZCpX2wnsAVKgM2FJXV6eyPjc3l7m5uTGgbVKVyspKBoBVVFQwY2Njrr6iooIBYOXl5UpDFri4uLDMzEzu+bvvvsvef/993o+ZChXAQCb7IYQPnYeq7uuw1U1NTdxjmUwGY2NqBiQDAyUHQvpo+fLl3M/Y2FgAwJ9//onAwEAAwMqVKxETEwMAOHfuHIKDgwG0TcZiaWnJQ8SE9Bx9TSGkG2ZmZtx0kgAQFRWF9957DwBgY2ODpKQkNDU1YcWKFQCA119/HXv37sU777yDiooKrFmzBgDw5ptv4ocffsALL7wAmUyG4OBglJSU6P6ACOkhGpWVkD7Izc2Fr68vbt68yXcohGgFXVYihBCihM4cCCGEKKEzB0IIIUooORBCCFFCyYEQQogSSg6EEEKUUHIghBCi5P8DbTHt6XatydsAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.08\n",
        "epochs = 30\n",
        "batch_size = 100\n",
        "\n",
        "# Split the original training set into a reduced training set and a\n",
        "# validation set. \n",
        "validation_split=0.4\n",
        "\n",
        "# Identify the feature and the label.\n",
        "my_feature=\"median_income\"  # the median income on a specific city block.\n",
        "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based \n",
        "# solely on the neighborhood's median income.  \n",
        "\n",
        "# Discard any pre-existing version of the model.\n",
        "my_model = None\n",
        "\n",
        "# Invoke the functions to build and train the model.\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, train_df, my_feature, \n",
        "                                    my_label, epochs, batch_size, \n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TKa11JK4Pm3f"
      },
      "source": [
        "## Task 2: Determine **why** the loss curves differ\n",
        "\n",
        "No matter how you split the training set and the validation set, the loss curves differ significantly. Evidently, the data in the training set isn't similar enough to the data in the validation set. Counterintuitive? Yes, but this problem is actually pretty common in machine learning. \n",
        "\n",
        "Your task is to determine **why** the loss curves aren't highly similar. As with most issues in machine learning, the problem is rooted in the data itself. To solve this mystery of why the training set and validation set aren't almost identical, write a line or two of [pandas code](https://colab.research.google.com/drive/1gUeYFsYmoyqpQJWq7krrZZNUFvBPwrJf) in the following code cell.  Here are a couple of hints:\n",
        "\n",
        "  * The previous code cell split the original training set into:\n",
        "    * a reduced training set (the original training set - the validation set)\n",
        "    * the validation set \n",
        "  * By default, the pandas [`head`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) method outputs the *first* 5 rows of the DataFrame. To see more of the training set, specify the `n` argument to `head` and assign a large positive integer to `n`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VJQcAZkwJt_p"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.3</td>\n",
              "      <td>34.2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>66.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.5</td>\n",
              "      <td>34.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>80.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.7</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>85.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>73.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>65.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>32.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6533.0</td>\n",
              "      <td>1217.0</td>\n",
              "      <td>4797.0</td>\n",
              "      <td>1177.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>144.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5110.0</td>\n",
              "      <td>1044.0</td>\n",
              "      <td>1938.0</td>\n",
              "      <td>724.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>112.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.2</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4397.0</td>\n",
              "      <td>931.0</td>\n",
              "      <td>1145.0</td>\n",
              "      <td>445.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>108.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4144.0</td>\n",
              "      <td>826.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>772.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>33.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1868.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>307.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0       -114.3      34.2                15.0       5612.0          1283.0   \n",
              "1       -114.5      34.4                19.0       7650.0          1901.0   \n",
              "2       -114.6      33.7                17.0        720.0           174.0   \n",
              "3       -114.6      33.6                14.0       1501.0           337.0   \n",
              "4       -114.6      33.6                20.0       1454.0           326.0   \n",
              "..         ...       ...                 ...          ...             ...   \n",
              "995     -117.1      32.5                 8.0       6533.0          1217.0   \n",
              "996     -117.1      34.6                 6.0       5110.0          1044.0   \n",
              "997     -117.1      34.2                22.0       4397.0           931.0   \n",
              "998     -117.1      34.0                24.0       4144.0           826.0   \n",
              "999     -117.1      33.6                 6.0       1868.0           289.0   \n",
              "\n",
              "     population  households  median_income  median_house_value  \n",
              "0        1015.0       472.0            1.5                66.9  \n",
              "1        1129.0       463.0            1.8                80.1  \n",
              "2         333.0       117.0            1.7                85.7  \n",
              "3         515.0       226.0            3.2                73.4  \n",
              "4         624.0       262.0            1.9                65.5  \n",
              "..          ...         ...            ...                 ...  \n",
              "995      4797.0      1177.0            4.0               144.4  \n",
              "996      1938.0       724.0            3.2               112.8  \n",
              "997      1145.0       445.0            4.5               108.4  \n",
              "998      2127.0       772.0            2.5                96.0  \n",
              "999       750.0       247.0            4.4               307.6  \n",
              "\n",
              "[1000 rows x 9 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Write some code in this code cell.\n",
        "train_df.head(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "EnNvkFwwK8WY"
      },
      "outputs": [],
      "source": [
        "#@title Double-click for a possible solution to Task 2.\n",
        "\n",
        "# Examine examples 0 through 4 and examples 25 through 29\n",
        "# of the training set\n",
        "train_df.head(n=1000)\n",
        "\n",
        "# The original training set is sorted by longitude. \n",
        "# Apparently, longitude influences the relationship of\n",
        "# total_rooms to median_house_value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rw4xI1ZEckI8"
      },
      "source": [
        "## Task 3. Fix the problem\n",
        "\n",
        "To fix the problem, shuffle the examples in the training set before splitting the examples into a training set and validation set. To do so, take the following steps:\n",
        "\n",
        "1. Shuffle the data in the training set by adding the following line anywhere before you call `train_model` (in the code cell associated with Task 1):\n",
        "\n",
        "```\n",
        "  shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
        "```                                    \n",
        "\n",
        "2. Pass `shuffled_train_df` (instead of `train_df`) as the second argument to `train_model` (in the code call associated with Task 1) so that the call becomes as follows:\n",
        "\n",
        "```\n",
        "  epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n",
        "                                      my_label, epochs, batch_size, \n",
        "                                      validation_split)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "ncODhpv0h-LG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zion/ML_crash_course/venv/lib/python3.9/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "153/153 [==============================] - 3s 12ms/step - loss: 42955.2539 - root_mean_squared_error: 207.2565 - val_loss: 31702.5840 - val_root_mean_squared_error: 178.0522\n",
            "Epoch 2/70\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 23287.9004 - root_mean_squared_error: 152.6037 - val_loss: 16222.0176 - val_root_mean_squared_error: 127.3657\n",
            "Epoch 3/70\n",
            "153/153 [==============================] - 2s 10ms/step - loss: 11552.1484 - root_mean_squared_error: 107.4809 - val_loss: 8466.5742 - val_root_mean_squared_error: 92.0140\n",
            "Epoch 4/70\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 7277.8979 - root_mean_squared_error: 85.3106 - val_loss: 7255.0449 - val_root_mean_squared_error: 85.1766\n",
            "Epoch 5/70\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 6989.0029 - root_mean_squared_error: 83.6003 - val_loss: 7254.5278 - val_root_mean_squared_error: 85.1735\n",
            "Epoch 6/70\n",
            "153/153 [==============================] - 2s 10ms/step - loss: 6989.3008 - root_mean_squared_error: 83.6020 - val_loss: 7254.2188 - val_root_mean_squared_error: 85.1717\n",
            "Epoch 7/70\n",
            "153/153 [==============================] - 1s 4ms/step - loss: 6988.3701 - root_mean_squared_error: 83.5965 - val_loss: 7255.0957 - val_root_mean_squared_error: 85.1768\n",
            "Epoch 8/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6987.4585 - root_mean_squared_error: 83.5910 - val_loss: 7254.5952 - val_root_mean_squared_error: 85.1739\n",
            "Epoch 9/70\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 6988.5371 - root_mean_squared_error: 83.5975 - val_loss: 7257.0142 - val_root_mean_squared_error: 85.1881\n",
            "Epoch 10/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6986.7207 - root_mean_squared_error: 83.5866 - val_loss: 7260.0210 - val_root_mean_squared_error: 85.2058\n",
            "Epoch 11/70\n",
            "153/153 [==============================] - 1s 4ms/step - loss: 6988.1382 - root_mean_squared_error: 83.5951 - val_loss: 7256.6055 - val_root_mean_squared_error: 85.1857\n",
            "Epoch 12/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6986.5093 - root_mean_squared_error: 83.5853 - val_loss: 7262.4976 - val_root_mean_squared_error: 85.2203\n",
            "Epoch 13/70\n",
            "153/153 [==============================] - 1s 4ms/step - loss: 6988.3887 - root_mean_squared_error: 83.5966 - val_loss: 7255.6787 - val_root_mean_squared_error: 85.1803\n",
            "Epoch 14/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.3989 - root_mean_squared_error: 83.5966 - val_loss: 7253.8438 - val_root_mean_squared_error: 85.1695\n",
            "Epoch 15/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6988.3662 - root_mean_squared_error: 83.5965 - val_loss: 7253.7305 - val_root_mean_squared_error: 85.1688\n",
            "Epoch 16/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.4004 - root_mean_squared_error: 83.5967 - val_loss: 7254.1313 - val_root_mean_squared_error: 85.1712\n",
            "Epoch 17/70\n",
            "153/153 [==============================] - 1s 4ms/step - loss: 6987.8608 - root_mean_squared_error: 83.5934 - val_loss: 7253.7705 - val_root_mean_squared_error: 85.1691\n",
            "Epoch 18/70\n",
            "153/153 [==============================] - 1s 4ms/step - loss: 6988.1665 - root_mean_squared_error: 83.5953 - val_loss: 7255.1831 - val_root_mean_squared_error: 85.1774\n",
            "Epoch 19/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6988.4946 - root_mean_squared_error: 83.5972 - val_loss: 7254.9736 - val_root_mean_squared_error: 85.1761\n",
            "Epoch 20/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6987.3184 - root_mean_squared_error: 83.5902 - val_loss: 7254.1577 - val_root_mean_squared_error: 85.1713\n",
            "Epoch 21/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6988.0571 - root_mean_squared_error: 83.5946 - val_loss: 7253.8657 - val_root_mean_squared_error: 85.1696\n",
            "Epoch 22/70\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 6988.3589 - root_mean_squared_error: 83.5964 - val_loss: 7254.0757 - val_root_mean_squared_error: 85.1709\n",
            "Epoch 23/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.6465 - root_mean_squared_error: 83.5981 - val_loss: 7255.4482 - val_root_mean_squared_error: 85.1789\n",
            "Epoch 24/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6988.4595 - root_mean_squared_error: 83.5970 - val_loss: 7253.6484 - val_root_mean_squared_error: 85.1684\n",
            "Epoch 25/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6986.9810 - root_mean_squared_error: 83.5882 - val_loss: 7261.7661 - val_root_mean_squared_error: 85.2160\n",
            "Epoch 26/70\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 6986.1909 - root_mean_squared_error: 83.5834 - val_loss: 7255.0942 - val_root_mean_squared_error: 85.1768\n",
            "Epoch 27/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6988.0854 - root_mean_squared_error: 83.5948 - val_loss: 7253.9961 - val_root_mean_squared_error: 85.1704\n",
            "Epoch 28/70\n",
            "153/153 [==============================] - 1s 4ms/step - loss: 6988.4873 - root_mean_squared_error: 83.5972 - val_loss: 7253.6616 - val_root_mean_squared_error: 85.1684\n",
            "Epoch 29/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6988.0547 - root_mean_squared_error: 83.5946 - val_loss: 7253.6401 - val_root_mean_squared_error: 85.1683\n",
            "Epoch 30/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.3174 - root_mean_squared_error: 83.5962 - val_loss: 7254.6572 - val_root_mean_squared_error: 85.1743\n",
            "Epoch 31/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.5547 - root_mean_squared_error: 83.5976 - val_loss: 7253.7212 - val_root_mean_squared_error: 85.1688\n",
            "Epoch 32/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.7593 - root_mean_squared_error: 83.5988 - val_loss: 7253.8740 - val_root_mean_squared_error: 85.1697\n",
            "Epoch 33/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6987.0859 - root_mean_squared_error: 83.5888 - val_loss: 7256.5220 - val_root_mean_squared_error: 85.1852\n",
            "Epoch 34/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.6514 - root_mean_squared_error: 83.5982 - val_loss: 7254.2100 - val_root_mean_squared_error: 85.1717\n",
            "Epoch 35/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6988.6553 - root_mean_squared_error: 83.5982 - val_loss: 7254.1992 - val_root_mean_squared_error: 85.1716\n",
            "Epoch 36/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6987.9214 - root_mean_squared_error: 83.5938 - val_loss: 7254.2720 - val_root_mean_squared_error: 85.1720\n",
            "Epoch 37/70\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 6987.9385 - root_mean_squared_error: 83.5939 - val_loss: 7257.3774 - val_root_mean_squared_error: 85.1902\n",
            "Epoch 38/70\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 6987.6426 - root_mean_squared_error: 83.5921 - val_loss: 7254.9976 - val_root_mean_squared_error: 85.1763\n",
            "Epoch 39/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.4644 - root_mean_squared_error: 83.5970 - val_loss: 7253.6943 - val_root_mean_squared_error: 85.1686\n",
            "Epoch 40/70\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 6987.8154 - root_mean_squared_error: 83.5932 - val_loss: 7257.5312 - val_root_mean_squared_error: 85.1911\n",
            "Epoch 41/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6989.1895 - root_mean_squared_error: 83.6014 - val_loss: 7253.6919 - val_root_mean_squared_error: 85.1686\n",
            "Epoch 42/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.4956 - root_mean_squared_error: 83.5972 - val_loss: 7253.7417 - val_root_mean_squared_error: 85.1689\n",
            "Epoch 43/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.2578 - root_mean_squared_error: 83.5958 - val_loss: 7254.4487 - val_root_mean_squared_error: 85.1730\n",
            "Epoch 44/70\n",
            "153/153 [==============================] - 2s 10ms/step - loss: 6989.2598 - root_mean_squared_error: 83.6018 - val_loss: 7254.6953 - val_root_mean_squared_error: 85.1745\n",
            "Epoch 45/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6987.9277 - root_mean_squared_error: 83.5938 - val_loss: 7256.5020 - val_root_mean_squared_error: 85.1851\n",
            "Epoch 46/70\n",
            "153/153 [==============================] - 2s 10ms/step - loss: 6986.3525 - root_mean_squared_error: 83.5844 - val_loss: 7259.6519 - val_root_mean_squared_error: 85.2036\n",
            "Epoch 47/70\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 6988.3970 - root_mean_squared_error: 83.5966 - val_loss: 7255.2637 - val_root_mean_squared_error: 85.1778\n",
            "Epoch 48/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6987.6895 - root_mean_squared_error: 83.5924 - val_loss: 7258.4966 - val_root_mean_squared_error: 85.1968\n",
            "Epoch 49/70\n",
            "153/153 [==============================] - 2s 10ms/step - loss: 6988.9893 - root_mean_squared_error: 83.6002 - val_loss: 7254.0640 - val_root_mean_squared_error: 85.17080s - loss: 6830.2256 - root_mean_squared_erro\n",
            "Epoch 50/70\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 6987.8545 - root_mean_squared_error: 83.5934 - val_loss: 7253.5312 - val_root_mean_squared_error: 85.1677\n",
            "Epoch 51/70\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 6987.4033 - root_mean_squared_error: 83.5907 - val_loss: 7254.9932 - val_root_mean_squared_error: 85.1762\n",
            "Epoch 52/70\n",
            "153/153 [==============================] - 1s 5ms/step - loss: 6987.9546 - root_mean_squared_error: 83.5940 - val_loss: 7253.6172 - val_root_mean_squared_error: 85.1682\n",
            "Epoch 53/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6987.1743 - root_mean_squared_error: 83.5893 - val_loss: 7256.4805 - val_root_mean_squared_error: 85.1850\n",
            "Epoch 54/70\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 6985.6294 - root_mean_squared_error: 83.5801 - val_loss: 7264.8945 - val_root_mean_squared_error: 85.2344\n",
            "Epoch 55/70\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 6988.9976 - root_mean_squared_error: 83.6002 - val_loss: 7253.5708 - val_root_mean_squared_error: 85.1679\n",
            "Epoch 56/70\n",
            "153/153 [==============================] - 2s 13ms/step - loss: 6987.5269 - root_mean_squared_error: 83.5914 - val_loss: 7258.7148 - val_root_mean_squared_error: 85.1981s - loss: 7031.0757 - root_mean_squared_erro\n",
            "Epoch 57/70\n",
            "153/153 [==============================] - 2s 13ms/step - loss: 6989.4541 - root_mean_squared_error: 83.6030 - val_loss: 7254.3184 - val_root_mean_squared_error: 85.1723\n",
            "Epoch 58/70\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 6987.4492 - root_mean_squared_error: 83.5910 - val_loss: 7256.6851 - val_root_mean_squared_error: 85.1862\n",
            "Epoch 59/70\n",
            "153/153 [==============================] - 1s 10ms/step - loss: 6986.5972 - root_mean_squared_error: 83.5859 - val_loss: 7261.0063 - val_root_mean_squared_error: 85.2115\n",
            "Epoch 60/70\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 6988.0322 - root_mean_squared_error: 83.5945 - val_loss: 7255.5884 - val_root_mean_squared_error: 85.1797\n",
            "Epoch 61/70\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 6988.0840 - root_mean_squared_error: 83.5948 - val_loss: 7254.2441 - val_root_mean_squared_error: 85.1719\n",
            "Epoch 62/70\n",
            "153/153 [==============================] - 1s 7ms/step - loss: 6988.1616 - root_mean_squared_error: 83.5952 - val_loss: 7255.3247 - val_root_mean_squared_error: 85.1782\n",
            "Epoch 63/70\n",
            "153/153 [==============================] - 1s 6ms/step - loss: 6988.5835 - root_mean_squared_error: 83.5977 - val_loss: 7254.0566 - val_root_mean_squared_error: 85.1708\n",
            "Epoch 64/70\n",
            "153/153 [==============================] - 3s 19ms/step - loss: 6987.5820 - root_mean_squared_error: 83.5918 - val_loss: 7255.0166 - val_root_mean_squared_error: 85.1764\n",
            "Epoch 65/70\n",
            "153/153 [==============================] - 2s 14ms/step - loss: 6987.4072 - root_mean_squared_error: 83.5907 - val_loss: 7261.5142 - val_root_mean_squared_error: 85.2145\n",
            "Epoch 66/70\n",
            "153/153 [==============================] - 2s 10ms/step - loss: 6988.1260 - root_mean_squared_error: 83.5950 - val_loss: 7256.9624 - val_root_mean_squared_error: 85.1878\n",
            "Epoch 67/70\n",
            "153/153 [==============================] - 3s 17ms/step - loss: 6986.8267 - root_mean_squared_error: 83.5872 - val_loss: 7253.6631 - val_root_mean_squared_error: 85.1684\n",
            "Epoch 68/70\n",
            "153/153 [==============================] - 2s 14ms/step - loss: 6988.5371 - root_mean_squared_error: 83.5975 - val_loss: 7256.0522 - val_root_mean_squared_error: 85.1825\n",
            "Epoch 69/70\n",
            "153/153 [==============================] - 1s 9ms/step - loss: 6987.8940 - root_mean_squared_error: 83.5936 - val_loss: 7253.6528 - val_root_mean_squared_error: 85.1684\n",
            "Epoch 70/70\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 6986.0327 - root_mean_squared_error: 83.5825 - val_loss: 7256.7808 - val_root_mean_squared_error: 85.1867\n",
            "69.02365112304688\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzs0lEQVR4nO3de1xUdf4/8NfcuIpgobABARqamquo6JaraboqWmLlGuqmqWG5mtn3uxmZLX7b/fnNLl+1i1aEorteEtPEdF0KL5k3UO55A0UXSEG8IAwwzOX8/hjmOAMzDCAzA87r+XicBzNnzpzzPjNneJ/P53PO5yMBIICIiAiA1NEBEBFR+8GkQEREIiYFIiISMSkQEZGISYGIiERyRwdwL8rKynDlyhVHh0FE1KEEBwejW7duZl/r0EnhypUriIiIcHQYREQdSnp6usXXWH1EREQiJgUiIhIxKRARkahDtykQkX106dIFixcvRkhICCQSiaPDoWYQBAGXL1/G6tWrcevWrWa/j0mBiKxavHgxTp06hffeew9ardbR4VAzyGQyTJw4EYsXL0ZcXFyz38fqIyKyKiQkBPv27WNC6EC0Wi327t2LkJCQFr2PSYGIrJJIJEwIHZBWq21xdZ9TJgX/R7pj/MJ58Ozi4+hQiIjaFadMCl1DHsYfXpkNL98HHR0KETXDAw88gMzMTGRmZuLq1asoLi4WnysUiibfO2jQIKxZs8bqNo4ePdomsT755JPYs2dPm6zLEZyyoVmtUgEAFK6uDo6EiJrj5s2bCA8PBwDExcWhqqoKH3/8sfi6TCazWL11+vRpnD592uo2hg0b1jbBdnBOWVLQqOoAAAo3JgWijmrDhg1Yt24dTpw4gQ8++AARERE4duwYMjIycPToUfTs2ROA6Zl7XFwcEhIScPDgQVy8eBGvvfaauL7Kykpx+YMHDyIpKQlnz57FP//5T3GZyMhInD17FqdOncKaNWtaVCKIjo5GTk4OcnNz8f777wMApFIpNmzYgNzcXOTk5GDx4sUAgNdeew2//PILsrOzsXXr1nv6nFqKJQUiapGoJYvx0KNhbbrOX8/lY/cHq1v8vsDAQDzxxBPQ6XTw8vLC8OHDodVqMXr0aKxYsQJTpkxp9J5HH30Uo0aNgpeXF86fP49169ZBo9GYLBMeHo6+ffvi119/xdGjRzFs2DCcOnUKX375JUaMGIHLly9jy5YtzY7zN7/5DVauXIlBgwbh1q1bSElJQVRUFIqKihAQEIB+/foBALy9vQEAsbGxCA0NRV1dnTjPXpyypKCuZVIguh8kJSVBp9MB0P9DTUpKQm5uLlatWoW+ffuafc/evXtRV1eHGzduoKysDH5+fo2WSUtLQ0lJCQRBQFZWFkJCQvDoo4/i0qVLuHz5MgC06Aw+IiIChw4dQnl5ObRaLTZv3owRI0bg0qVL6N69Oz755BOMGzcOd+7cAQDk5ORg8+bNmDFjRqOEZWs2KykkJCTg6aefRllZmZgF4+LiEBMTg+vXrwMAli5din/9618A9Jlx7ty50Gq1WLRoEVJSUmwVmlFJwcVm2yC6X7XmjN5WlEql+Phvf/sbDh48iOeeew7BwcE4dOiQ2feo6n//gP6STbm88b/B5izTFm7fvo3+/ftj3LhxePXVVzF16lTMnTsXEydOxIgRI/DMM8/gnXfeQb9+/ex2SbDNSgqJiYkYP358o/mrVq1CeHg4wsPDxYTQu3dvREdHo2/fvhg/fjzWrl0LqdR2hRiWFIjuP97e3igpKQEAvPTSS22+/vPnz6N79+4IDg4GALzwwgvNfm9aWhqefPJJPPjgg5BKpZg2bRoOHz4sPt+5cyeWLVuGgQMHQiKRICgoCIcOHcJbb70Fb29vdOrUqc33xxKblRSOHDkifnjWREVFYdu2bairq8Ply5dRUFCAIUOG4MSJEzaJTSwpsKGZ6L7xwQcfYOPGjVi2bBn27t3b5uuvra3Fn//8Z+zfvx9KpbLJMQlGjx6NoqIi8fkf//hHxMbG4uDBg5BIJNi7dy+Sk5Px29/+Fhs2bBBPgt9++23IZDL885//hLe3NyQSCT755BNUVFS0+f40RbDVFBwcLOTm5orP4+LihMLCQiE7O1tISEgQfHx8BADCp59+KsyYMUNc7uuvvxaef/55s+uMiYkR0tPThfT0dKGwsLBVcbm4uwsf5x4XRs6abrN958Tpfpo2bdrk8Bjaw+Tp6Sk+/vzzz4XFixc7PKbWfHfp6ekWl7drQ/O6devQo0cPDBgwAFevXjW5zri54uPjERERgYiICJSXl7cqDk2d/pJUOUsKRNQCMTExyMzMxC+//AJvb298+eWXjg6pzdn1ktSysjLxcXx8PL7//nsAQElJCYKCgsTXAgMDxbpBW9BptdCqNWxTIKIWWb16NVavXu3oMGzKriUFf39/8fGzzz6LvLw8AEBycjKio6Ph4uKCkJAQhIWFIS0tzaaxqFUqtikQETVgs5LCli1bMHLkSPj6+qKoqAhxcXEYOXIkBgwYIA7+8MorrwAAzpw5g+3bt+PMmTPQaDRYsGCBeO2xrahVKpYUiIgasFlSmD59eqN569evt7j8ihUrsGLFCluF04i6VsX7FIiIGnDKO5oBlhSIiMxx3qRQy6RA1FEcOHAAY8eONZn3+uuvY+3atRbfc/DgQQwaNAiAvmsLc30IxcXF4b//+7+b3HZUVBR69+4tPv+f//kfjB49uiXhm9Veu9h23qTAhmaiDmPr1q2Ijo42mRcdHd3s/ocmTpzY6hvAJk+ejD59+ojP4+LikJqa2qp1dQROmxQ0qjqWFIg6iB07dmDixInigDrBwcF46KGHcOTIEaxduxbp6enIy8vD8uXLzb6/sLAQDz6oH1Rr6dKlOH/+PI4cOYJevXqJy7z88stIS0tDVlYWduzYAXd3dzz++OOYNGkSPvzwQ2RmZqJ79+7YsGEDnn/+eQDAU089hYyMDOTk5CAhIQEuLi7i9pYvX47Tp08jJyfHZDvWOLqLbafsOhvQlxTcOtuvPxGi+8WqVS+j/4DubbrO7KxLeOONry2+fuvWLaSlpSEyMlK8hH379u0AgHfeeQe3bt2CVCpFamoq+vXrh9zcXLPrGThwIKKjozFgwADI5XJkZGSIA/Ds3LkTX3+tj+Fvf/sb5s6di88++wzJycn4/vvv8e2335qsy9XVFYmJiRg9ejTy8/OxceNGzJ8/Xxzlrby8HIMGDcL8+fPxl7/8BTExMVY/h/bQxbbTlhTY0EzUsRhXIRlXHU2dOhWnT59GZmYm+vbta1LV09Dw4cOxa9cu1NTUoLKyEsnJyeJrjz32GH766Sfk5ORgxowZFrveNujVqxcKCwuRn58PANi4cSNGjBghvr5z504A+pHfQkJCmrWP7aGLbectKbChmahVmjqjt6Xdu3eLvSx7eHggIyMDISEh+Mtf/oKIiAjcvn0bGzZsgJubW6vWn5iYiMmTJyMnJwezZs3CyJEj7yleQ/fbbdH1tj272HbykgLvUyDqKJRKJQ4ePIj169eLpYTOnTtDqVSioqIC3bp1Q2RkZJPr+OmnnzB58mS4ubmhU6dOeOaZZ8TXvLy8cPXqVcjlcsyYMUOcX1lZCS8vr0brOn/+PEJCQtCjRw8AwIsvvojDhw/f0z62hy62WVIgog5j69at+O6778RqpJycHGRmZuLcuXMoKirC0aNHm3x/ZmYmvvnmG2RnZ6OsrMyk++t3330XJ0+exPXr13Hy5EkxEWzbtg3x8fFYtGiRyfCeKpUKs2fPRlJSEuRyOdLT0/HFF1+0aH/aaxfbDu/atbVTU92/WpsmvD5fWHn6sMP3gROnjjCx6+yOO7XrrrPbE41KBbmLCyQ2HOGNiKijcdr/iBynmYioMSYFtisQWSUIAmQymaPDoBaSyWQQBKFF73HepFDLpEDUXJcvX8bEiROZGDoQmUyGiRMn4vLlyy16n/NefVRfUpCz+ojIqtWrV2Px4sV4/vnnIZFIHB0ONYNh3JqWjhTnvEnBUFJgp3hEVt26dQtxcXGODoPswHmrj9imQETUiBMnhToATApERMacOCmw+oiIqCGbJYWEhASUlpaa7cL2v/7rvyAIgti/OQCsWbMG+fn5yM7ORnh4uK3CEvHqIyKixmyWFBITEzF+/PhG8wMDAzF27FhcuXJFnBcZGYmwsDCEhYVh3rx5WLduna3CErGkQETUmM2SwpEjR3Dz5s1G81etWoUlS5aY3FARFRWFTZs2AQBOnjwJHx8f+Pv72yo0AICGJQUiokbs2qYwadIklJSUICcnx2R+QECASU+BxcXFCAgIMLuOmJgYpKenIz09Hb6+vq2O5e59CkwKREQGdrtPwd3dHUuXLsXYsWPvaT3x8fGIj48HAJNub1uKl6QSETXWZElBKpXiww8/bJMN9ejRA6GhocjOzkZhYSECAwORkZEBPz8/lJSUICgoSFw2MDAQJSUlbbJdS8RLUtmmQEQkajIp6HQ6/P73v2+TDeXl5cHPzw+hoaEIDQ1FcXExBg4ciNLSUiQnJ2PmzJkAgKFDh6KiogLXrl1rk+1aIuh00KjVLCkQERmxWn2UmZmJ3bt3IykpCUqlUpy/a9euJt+3ZcsWjBw5Er6+vigqKkJcXBzWr19vdtl9+/ZhwoQJKCgoQHV1NWbPnt3C3Wgdjr5GRGTKalJwc3PDjRs38NRTT4nzBEGwmhSmT5/e5OuhoaEmzxcuXGgtlDanVqlYfUREZMRqUpgzZ4494nAIlhSIiExZvSQ1ICAAO3fuRGlpKUpLS7Fjxw6Ll4t2NCwpEBGZspoUNmzYgOTkZDz00EN46KGHsGfPHmzYsMEesdmcun6cZiIi0rOaFLp27YrExERotVpotVps3LgRXbt2tUdsNqepZUmBiMiY1aRw48YNzJgxA1KpFFKpFDNmzMCNGzfsEZvNqevq2KZARGTEalKYM2cOpk6dimvXruHq1auYMmWK3S4ZtTU2NBMRmWry6iOpVIoVK1YgKirKXvHYFRuaiYhMWb2jOTg4GAqFwl7x2BVLCkREpqzep3Dp0iUcPXoUycnJJnc0r1q1yqaB2QNLCkREpqwmhYsXL+LixYuQSqXw8vKyR0x2o1axpEBEZMxqm0LPnj3xpz/9yV7x2JW6VgW5K+9TICIycOo2BU1dHeQKBSRSu441RETUbjl3m4LRkJx1NTUOjoaIyPGcvk0B0A+0w6RARNSMpPDee+81mieTyWwSjL0ZlxSIiKiJNoUjR46Ijzdt2mTyWlpamu0isiPjkgIRETWRFDw9PcXHjz32mMlrEonEdhHZEUsKRESmLCYFQRDMPjb3vKNiSYGIyJTFNgUfHx9MnjwZUqkUPj4+ePbZZwHoSwne3t52C9CWNPVJgWMqEBHpWUwKhw8fxqRJk8THzzzzjPjaTz/9ZPvI7IAlBSIiUxaTwr2OzZyQkICnn34aZWVl6NevHwD9lUxRUVHQ6XQoKyvDSy+9hKtXrwIA1qxZgwkTJqC6uhovvfQSMjMz72n7zSEmBbYpEBEBaMZ4Cq2VmJiI8ePHm8z78MMP0b9/f4SHh+P777/HX//6VwBAZGQkwsLCEBYWhnnz5mHdunW2CsuE2NDMkgIREQAbJoUjR47g5s2bJvMqKyvFx56enmKDdVRUlHjZ68mTJ+Hj4wN/f39bhSZiSYGIyJTVm9fa2t///nfMnDkTFRUVGDVqFAAgICAARUVF4jLFxcUICAjAtWvXGr0/JiYG8+bNAwD4+vreUyy8JJWIyJTFpGC42siSXbt2tWqDy5Ytw7JlyxAbG4uFCxdi+fLlLXp/fHw84uPjAQDp6emtisGADc1ERKYsJgXD1UbdunXDE088gQMHDgAARo0ahWPHjrU6KRhs3rwZ+/btw/Lly1FSUoKgoCDxtcDAQJSUlNzT+ptDo6oDwJICEZGBxTaFOXPmYM6cOVAoFOjTpw+mTJmCKVOmoG/fvq3uSvuRRx4RH0dFReHcuXMAgOTkZMycORMAMHToUFRUVJitOmprgiBAU1cHBcdUICIC0Iw2haCgIJN/0KWlpXj44YetrnjLli0YOXIkfH19UVRUhLi4OEyYMAG9evWCTqfDlStX8OqrrwIA9u3bhwkTJqCgoADV1dWYPXv2PexSy+gH2mFJgYgIaEZSSE1Nxf79+7F161YAwAsvvIAff/zR6oqnT5/eaN769estLr9w4UKr67QFjtNMRHSX1aTw2muvYfLkyRgxYgQA4KuvvsJ3331n67hs6oEHvNCnTxBOn77IcZqJiIw065LUjIwMVFZWIjU1Fe7u7ujUqROqqqpsHZvNjB7dH99sfwt9+/wZ6lomBSIiA6s3r7388svYsWMHvvzySwD6ewo6eklBqawFAHTq5MbqIyIiI1aTwoIFCzBs2DDcuXMHAFBQUIBu3brZPDBbqqrSJwVPTzeWFIiIjFhNCiqVCmq1Wnwuk8k6/HgKhpKCp6db/SWpTApEREAzksLhw4fx9ttvw93dHWPGjEFSUhL27Nljj9hsxqT6iCUFIiKR1aTw1ltv4fr168jNzcUrr7yCffv2YdmyZfaIzWZMqo/YpkBEJGry6iOpVIpffvkFvXv3xtdff22vmGzOuProukoFOe9oJiICYKWkoNPpcP78eZN+ie4HrD4iIjLP6n0KXbp0wS+//IK0tDQolUpxflRUlE0Ds6W6Og3Uao2++qiC1UdERAZWk8K7775rjzjsTqmshaenK9SlLCkQERlYTQo//fSTPeKwO6VShU6d3KGuq4JMLodULoNOo3V0WEREDmX16qOhQ4ciLS0NlZWVUKlU0Gg0qKiosEdsNqVU1sLD0xUaw+hrLiwtEBFZTQqfffYZpk2bhvz8fLi7u+Pll1/G559/bo/YbKqqqla8JBXg6GtEREAzkgIAXLx4ETKZDDqdDomJiRg/fryt47I5pbJWvPoI4OhrRERAM9oUqquroVAokJWVhZUrV+Lq1auQSpuVS9o1pbIWXbp0YkmBiMiI1f/uL774ImQyGRYuXAilUomgoCA8//zz9ojNphpVH7GkQERkvaTwn//8BwBQW1uL9957z+YB2Qurj4iIGrOaFC5dumS2V9QePXrYJCB7qVaq2NBMRNSA1aQwePBg8bGbmxv++Mc/4oEHHrC64oSEBDz99NMoKytDv379AAAffPABnnnmGdTV1eHixYuYPXu2eHlrbGws5s6dC61Wi0WLFiElJaW1+9QsVVU19UmhDgAgZ0mBiMh6m8LNmzfF6ddff8WaNWswceJEqys2d5XSDz/8gMceewz9+/fHhQsX8PbbbwMAevfujejoaPTt2xfjx4/H2rVrbd6YrVTWwsPDFVq1Piko2CkeEZH1kkJ4eLj4WCqVYvDgwZDLrQ/tfOTIEQQHB5vM++GHH8THJ06cwJQpUwDo+1Hatm0b6urqcPnyZRQUFGDIkCE4ceJEs3ekpZRKfbWRXKKvGmObAhFRM5LCxx9/LD7WaDS4fPkypk6des8bnjNnDr755hsA+nGfjRNAcXExAgIC7nkbTamqqgEAuMj0z9mmQETUjKTw1FNPtflGly5dCo1Gg82bN7f4vTExMZg3bx4AwNfXt9UxGEoKrgp9NRVLCkREzUgKb7zxRpOvr1q1qkUbnDVrFp5++mmMHj1anFdSUmIyZkNgYCBKSkrMvj8+Ph7x8fEAgPT09BZt25hhTAVXuQQASwpEREAzGpoHDx6M+fPnIyAgAAEBAXj11VcxcOBAeHl5wcvLq0UbGzduHJYsWYJJkyahpqZGnJ+cnIzo6Gi4uLggJCQEYWFhSEtLa/netIBhSE6WFIiI7rJaUggMDMTAgQNRVVUFAFi+fDn27t2LF198scn3bdmyBSNHjoSvry+KiooQFxeHt99+G66urmKD84kTJzB//nycOXMG27dvx5kzZ6DRaLBgwQLodLo22D3L7o6+5q4fp5lJgYjIelLw8/NDXV2d+Lyurg5+fn5WVzx9+vRG89avX29x+RUrVmDFihVW19tW7o7T7KpPCqw+IiKynhQ2bdqEtLQ07Nq1CxKJBFFRUUhMTLRDaLZlqD7y9NR3dSF34X0KRERWk8KKFSvwr3/9C8OHD4cgCJg9ezaysrLsEJpt3S0puLGkQERUz2JDs7u7u3iTWmZmJvbv3w+ZTIbQ0FC7BWdLd9sU9CUFtikQETWRFPbv34+QkBAA+s7vjh8/ju7du2PBggX43//9X3vFZzOG+xRYUiAiustiUujSpQsKCgoA6O8t2Lp1KxYtWoTIyMhm9X3U3ul0OtTUqO42NLOkQERkOSkYd5f91FNPiZeRqtVqm18uai9KpQqdOrlDo6pjUiAiQhMNzTk5Ofjwww9RUlKCRx55ROzK2tvb227B2ZpSWQsPTzeoK1XwetB6d+BERPc7iyWFmJgYlJeXIyQkBGPHjhXvQO7Tpw8++ugjuwVoS/ohOV3Z0ExEVM9iSaG2thYrV65sNP/48eM4fvy4TYOyF/2QnPo7muUcT4GIyHrfR/czpZIlBSIiY06dFPTVR7wklYjIwKmTgr76yI2XpBIR1bPazUVYWBjefPNNBAcHmwzDaTweQkdVrdSXFDSqOkhlMsjkcmg1GkeHRUTkMFaTQlJSEr744gvEx8dDq9XaIya7EauPavV3NyvcXKGtYlIgIudlNSloNBp88cUX9ojF7oyrjwD9QDu1VUoHR0VE5DhW2xT27NmD+fPnw9/fH126dBGn+4FSqYJCIYegVQMAL0slIqdntaQwa9YsAMCbb74pzhMEAT169LBdVHZSVaW/IU8OfbcdbGwmImdnNSl0797dHnE4hKGnVIVU388TL0slImdnNSkAQN++fdGnTx+4ubmJ8/7xj3/YLCh7MYypICYFV7emFiciuu9ZTQp//etfMXLkSPTp0wf79u1DZGQkfv755/sqKbjUt6ywpEBEzs5qQ/OUKVMwevRoXLt2DXPmzEH//v2b1VNqQkICSktLkZuba7KuvLw8aLVaDBo0yGT52NhY5Ofn49y5cxg7dmwrdqXlDOM0uyr0HwPbFIjI2VlNCjU1NRAEARqNBl5eXigrK0NQUJDVFScmJmL8+PEm8/Ly8vDcc8/hp59+Mpnfu3dvREdHo2/fvhg/fjzWrl0LqdT2N1uLJQW5BABLCkREVquPTp06BW9vb8THx+P06dOoqqpqVi+pR44cQXBwsMm8c+fOmV02KioK27ZtQ11dHS5fvoyCggIMGTIEJ06caOZutI4hKbgakgJLCkTk5KwmhQULFgAAvvzyS+zfvx+dO3c2qRJqCwEBASYJoLi4GAEBAWaXjYmJwbx58wAAvr6+97RdQ/WRm4sMAO9TICJqVh3NjBkz8O677+LKlSu4ffs2IiIibB2XRfHx8YiIiEBERATKy8vvaV1iSaE+KbCkQETOzmpSWLt2LR5//HFMmzYNAFBZWYnPP/+8TYMoKSkxaacIDAxESUlJm27DHMN9Cm5MCkREAJqRFIYOHYqFCxeitlZ/Vn379m24uLRtNUtycjKio6Ph4uKCkJAQhIWFIS0trU23YU5NjQo6nQ4e7goAbGgmIrLapqBWqyGVSiEI+hu8fH19odPprK54y5YtGDlyJHx9fVFUVIS4uDjcvHkTn376Kbp27Yq9e/ciKysL48ePx5kzZ7B9+3acOXMGGo0GCxYsaNY22oJSebenVJYUiMjZWU0Kn3zyCXbt2oVu3brh73//O6ZMmYJly5ZZXfH06dPNzv/uu+/Mzl+xYgVWrFhhdb1tTalUwdPTDdc5+hoRkfWksGXLFpw+fRqjR4+GRCLB5MmTLV5a2hFVVdXAs5MbfmVJgYjIclIw7h67rKwMW7duNXnt1q1bto3MTgwlhbraWriwpEBETs5iUigvL0dxcTE09cNTSiQS8bX7petswNCm4Iqa8kq4d+7s6HCIiBzKYlL45JNPMGrUKBw9ehRbt27Fzz//bM+47KaqSj/6WvXFO/DwZlIgIudm8ZLUN954AwMGDEBSUhJefPFFZGZmYuXKlQgJCbFjeLZnGJKz+g6TAhGR1fsUDh06hCVLluCLL77A7NmzMWbMGHvEZTeGS1Krb1cwKRCR07NYfeTh4YGoqCi88MIL6Nq1K3bu3IlBgwahqKjInvHZnLKqPilU3IGbVydIpFIIdrpHgoiovbGYFMrKypCfn49t27YhPz8fgiBg8ODBGDx4MABg165ddgvSlsTqo4o7kEqlcOvUCTV37jg6LCIih7CYFJKSkiAIAnr16oVevXqZvCYIwn2UFFTw8HBFdYU+EXh4d2ZSICKnZTEpzJ49255xOIxSWQupVApdbTUAfVK4cX/VkBERNZvthzdr56qqagAAEo2+x1Q2NhORM3P6pGDoPluiqQPApEBEzs1qUjDXTXZbd53tSIaBdiQ6NQAmBSJyblaTgrnxmJszRnNHYRiSUwEtACYFInJuFhua/fz8EBAQAHd3dwwYMEDs+6hz587w8PCwW4C2ZigpuLspUFNZBQ/2f0RETsxiUhg3bhxeeuklBAYG4v/+7//E+ZWVlVi6dKldgrMHQ1Iw3MDGkgIROTOLSWHTpk3YtGkTnnvuOezcudOeMdmVofqoUyd3ff9HPkwKROS8rLYppKam4uOPP0Z6ejrS09Px0UcfofN9VMVyt6TgihqWFIjIyVlNCgkJCaisrMTUqVMxdepU3LlzBxs2bLBHbHbRqProPkp4REQtZXU4zh49emDKlCni8/feew+ZmZk2DcqeDPcpdOrkhmKWFIjIyVktKdTU1GDYsGHi8yeeeAI1NTVWV5yQkIDS0lLk5uaK87p06YKUlBRcuHABKSkp8PHxEV9bs2YN8vPzkZ2djfDw8BbuRuup1RrU1alNGpqNR5kjInImVpPC/Pnz8fnnn6OwsBCXL1/GZ599hldeecXqihMTEzF+/HiTebGxsUhNTUXPnj2RmpqK2NhYAEBkZCTCwsIQFhaGefPmYd26da3cndYxjNNcXXEHUpkMrp73zyW3REQtYbX6KDs7GwMGDICXlxcA/SWpzXHkyBEEBwebzIuKisLIkSMBABs3bsShQ4cQGxuLqKgobNq0CQBw8uRJ+Pj4wN/fH9euXWvJvrRaVVVN/ehrJQD0N7DVVintsm0iovbEakmhc+fO+Pjjj3HgwAEcOHDgnq4+8vPzE//RX7t2DX5+fgCAgIAAk8F7iouLERAQYHYdMTEx4pVQvr6+rYqjIaVSBY/6kgLAu5qJyHlZTQrr16+32dVHgiC0+D3x8fGIiIhAREQEysvL2yQOcUhOJgUicnJ2vfqotLRUrBby9/dHWVkZAKCkpARBQUHicoGBgSgpKWnVNlqjquru6GsAeFkqETktm119ZE5ycjJmzZoFAJg1axZ2794tzp85cyYAYOjQoaioqLBbewLQuKTgzpICETkpqyWF+fPnY+PGjfD29oZEIsHNmzfFf+xN2bJlC0aOHAlfX18UFRUhLi4O77//PrZv3465c+fiypUrmDp1KgBg3759mDBhAgoKClBdXW33Ud+UylqEhHRj9REROb0WX32kVCoRHR1tcv+BOdOnTzc7f8yYMWbnL1y40FooNqNUqtCpkzu0ajVU1dVMCkTktCxWH3l5eSE2NhaffvopxowZg8rKSsycORMFBQXiGf79QllVA09PVwBgT6lE5NQslhT+8Y9/4NatWzh+/DhiYmLwzjvvQCKR4Nlnn0V2drY9Y7Q5Q5sCwKRARM7NYlLo3r07fvvb3wIAvv76a1y9ehUPP/wwVCqV3YKzF6VSBTc3F8hkUnaKR0ROzWL1kVqtFh/rdDoUFxfflwkB0N/RDHCgHSIiiyWF/v37o6KiAgAgkUjg7u6OiooKSCQSCIIAb29vuwVpa4aeUj093fQD7TApEJGTspgU5HKrFybdNzjQDhGRntWb15yByZCcFXcgd3GBi7ubg6MiIrI/JgU0Hn0NYFcXROScmBRgWn0kJgWf+6fNhIiouZgU0Lj6CGBXF0TknJgU0KCkcIdJgYicF5MCLLQpMCkQkRNiUoBx9RGTAhE5NyYFANXVd29eU9eqoFapePURETklJgXohwWtrlaxUzwicnpMCvWUSv2QnIA+KXD0NSJyRkwK9aqqauHV2QMA2P8RETktJoV6Z878BwMGdAcA9n9ERE6LSaHe8WPn0Lfvw/Dx8UR1RSWTAhE5JYckhUWLFiE3Nxd5eXl4/fXXAQBdunRBSkoKLly4gJSUFPj4+Ng1pqNHzwAAHn/8UShvV/DqIyJySnZPCn379kVMTAyGDBmC/v374+mnn0aPHj0QGxuL1NRU9OzZE6mpqYiNjbVrXOnp+dBotHjiid6orrgDF3c3yF1d7RoDEZGj2T0p9O7dGydPnkRNTQ20Wi0OHz6M5557DlFRUdi4cSMAYOPGjZg8ebJd46quViEz8xKeGNb7blcXnb3sGgMRkaPZPSnk5eVh+PDheOCBB+Du7o4JEyYgKCgIfn5+uHbtGgDg2rVr8PPzs3doOH7sLIYO7YW6qioAvKuZiJyP3ZPCuXPnsHLlSqSkpGD//v3IysqCVqtttJwgCGbfHxMTg/T0dKSnp8PX17dNYzt69Cw8PFwR3M0dAJMCETkfhzQ0r1+/HoMHD8aTTz6JW7du4cKFCygtLYW/vz8AwN/fH2VlZWbfGx8fj4iICERERKC8vLxN4zp27CwA4LGe3QAwKRCR83FIUujatSsAICgoCM899xy2bNmC5ORkzJo1CwAwa9Ys7N692+5xlZTcwJUrZRjwWAAAjr5GRM5H7oiNfvvtt3jwwQehVquxYMECVFRU4P3338f27dsxd+5cXLlyBVOnTnVEaDh27CxGjHgMl28JLCkQkdNxSFIYMWJEo3k3b97EmDFjHBCNqWNHz2LatCfhcUvN/o+IyOnwjuYGjh07BwDwlVbCk+M0E5GTcUhJoT3LySlEVVUNfuMmY/URETkdlhQa0Gp1OHnyAoK82dBMRM6HScGMY0fPIqCLAj4PMCkQkXNhUjDj2LGzkEolCHuYSYGInAuTghnHj5+DTiegh5+bo0MhIrIrJgUz7typxuVf7+BhHwlkcrbFE5Hz4H88C3LOXUPkKB8sfvOPqLp5C4aumIz7ZDI8lkgk9VPj9RgWl0olkMmkkEql4mPjSSKRQKvVmUwymRQuLnIoFDK4uCggkQB1dRrU1WmgUqlRV6eBVquDTqeDIED8a67fKIm54BrtAyCVSs3uh/H+CIJQPzX9GUokpp+NVCoVt6nTCdDpdNDpBMjlMri5KeDm5gI3NwUUCnmD/VRDq9U12nbD/Wz43HjbxvtvHLu590ilEpPvSyKRQKfT1X/Wgvg5N9zXhuvRv18CmUxW/x3DZB06nSB+FsYxyeVSyOUyyOX692m1Omg02vpJ/32b20/jz7zxd6Hfp7v7J210DEqlEmg0+m2p1RpoNFpxP+4uI61/XSvGpNMJRp+r/rHhODI+nhruZ8PfgYuLvP4Y0B8HUqkU1dUqKJW1UCprUV2tglQqhUIhg0Kh/11IJBIxDrVaC61WJ27XeD8VClmjz7SuTgO1WiPuiyF+Q5zmjh/jY8/cMjKZFK6uCri4yOHiIodcLoNWqxO3oVZrGv3OtVqdSaxSqcToNyJAq9V/3w2/r1OnCsRxYNoSk4IF320/hMljeuHDFdMdHQoAQK3WAAAUivv/K9NqtZDJZI4OgxxErdagtrYOggB4erp26GPBlsfyyvd3MCnY06b473H2yh3M+ug9lJw9j38s+Su0dWrxdcPZj0QiaXT2cHcZifjXcEavP+MVGp0pCIJQfwYgE88EDGcWarXWZL36sxAFXF0V4lmt8ZmZMUN8gPmzYuNljEsalkob5s68zW3LwPDZGJ9dG95vOIs2/BOorVVDpVJDEARIpVLxbMvVVSGWpoxLH+b2paG7JQt9HMaxG9bTMGbjUoHhLM3wGRvObi1ty5jhuzWsR79fpusxxGA4iwdQf5auqz8L10EqNZQcpFAo5Gb31fg7s1SKM5RODGfCpseg/oxff1YtF7dlvJz+bNq0JGM4W29YWjEuURmXRo330/g3odXqoFLpv3/DZ27g6qqAp6cbPDxc68+69b8JtVoDQUCjkoAhZuMSmaHkYyhpGfbTUOqQy2Umx5bhbL3h76Hhb6DhMhqNDnV1arGkayhNGG+vcQlNavLdGEqCxiWHxjUJWtTU1Jk9DtuC0FGn9PR0m2+j/7jRwofZR4XZn6wUpDKZw/eZEydOnO51aup/Jxuarcj+dyp2/r+P8NioEfhjnH2HCCUisjdWHzXD8e274PVAF4xbEINHhz8OQasDGpbgBUAQdHeLmkL9bMGQgOuLnVKjBiud/jXB0LAlFq2NqzXuvg5BgEQqrV9OKq6rtcTqjvo/xvvUZMN0/b4a3iQua6ax1dr6DOsUxEZIXf369ftreF3/2UkBCUz23VoDuqV4mponVjcZvh9B0G+z/vuzui9G339Ty4nbN1MdZ/LdGKoFJRJIjD5kAaafkdl9M3qPYXnjz7s5x5dxLHe/C4m4/vqFTPb9bjzGcTX+7MQYDJ+38XpQ32Asl0EilUJaXzcv6HQm25GI1af648NwfOp0OpPv0Pg3efdzl5r/Pps4lhsy3WdzX3zjY9V4vyGg/rNufHw1XLegE8T9P7FjNw5v2moxrtZiUmimlC/WQ1lxBw/1fEScJ9QfABLc/YGYfqkS8eAzThqGH7rhh2f4h2f4sg0HsvFBIpFKIQHEA91kXU2p37bZ+TAcqHcXMvnn0vB9krvLS6QSM4nPzD8n49VZ/MdlqKuVmvwDFMM0JEhDu4fxD91CnIZ1NxWPpbjuJu+7n3/Dz9zavlj+4O8GaJL4jb/LBt9Nw0R595+ahcRotOmG7zFJrMafvaXjC6ax6GNu/Dk03nejuBrGY7Sjpt+/8e9IX4mh02qh02oh6HTQ1bc1mHw/Egl0Oq1JQgHQKLkZtyNBIhGPpab+mTfn2DH5TVhKLo2SZOP9NpvATNq/pKbflUSCO+U3zAR075gUWuDo1h2ODoGIyKbYpkBERCImBSIiEjEpEBGRiEmBiIhETApERCRiUiAiIhGTAhERiZgUiIhI1NRtl+1eWVkZrly50qxlfX19UV5ebuOI2lZHi7mjxQswZnvpaDF3tHiBlsUcHByMbt26WXy9xT3sdcTJHj2qOnvMHS1exsyY75d42zJmVh8REZGISYGIiEROkxS++uorR4fQYh0t5o4WL8CY7aWjxdzR4gXaLuYO3dBMRERty2lKCkREZB2TAhERie77pDBu3DicO3cO+fn5eOuttxwdjkUJCQkoLS1Fbm6uOK9Lly5ISUnBhQsXkJKSAh8fH8cF2EBgYCAOHDiAX375BXl5eVi0aBGA9h2zq6srTp48iaysLOTl5WH58uUAgJCQEJw4cQL5+fnYtm0bFAqFYwNtQCqVIiMjA3v27AHQ/uMtLCxETk4OMjMzkZ6eDqB9HxcA4O3tjaSkJJw9exZnzpzB7373u3Ydc8+ePZGZmSlOFRUVeP3119ssZodfX2urSSqVCgUFBUJoaKigUCiErKwsoXfv3g6Py9w0fPhwITw8XMjNzRXnrVy5UnjrrbcEAMJbb70lvP/++w6P0zD5+/sL4eHhAgChU6dOwvnz54XevXu365gBCJ6engIAQS6XCydOnBCGDh0qfPPNN8ILL7wgABDWrVsnvPrqqw6P03h64403hM2bNwt79uwRALT7eAsLC4UHH3zQZF57Py4SExOFuXPnCgAEhUIheHt7t/uYDZNUKhWuXr0qPPzww20Vs+N3ylbT7373O2H//v3i89jYWCE2NtbhcVmagoODTZLCuXPnBH9/fwHQ/xM+d+6cw2O0NH333XfCmDFjOkzM7u7uwunTp4UhQ4YI169fF2QymdljxtFTQECA8OOPPwqjRo0Sk0J7jhcwnxTa83HRuXNn4dKlS43mt+eYjac//OEPws8//9xmMd/X1UcBAQEoKioSnxcXFyMgIMCBEbWMn58frl27BgC4du0a/Pz8HByRecHBwQgPD8fJkyfbfcxSqRSZmZkoKyvDDz/8gIsXL+L27dvQarUA2t8xsnr1aixZskQ/yDyABx98sF3HCwCCICAlJQWnTp1CTEwMgPZ9LIeGhuL69evYsGEDMjIyEB8fDw8Pj3Yds7Ho6Ghs3boVQNt8zvd1UrjfCILg6BAa8fT0xLfffovFixejsrKy0evtLWadTofw8HAEBgZiyJAhePTRRx0dkkUTJ05EWVkZMjIyHB1Ki/z+97/HoEGDEBkZiQULFmD48OGNlmlPx4VcLsfAgQOxbt06DBw4EEqlErGxsY2Wa08xGygUCkyaNAlJSUlmX29NzPd1UigpKUFQUJD4PDAwECUlJQ6MqGVKS0vh7+8PAPD390dZWZmDIzIll8vx7bffYvPmzdi1axeA9h+zQUVFBQ4ePIjHH38cPj4+kMlkANrXMTJs2DBMmjQJhYWF2LZtG5566imsWbOm3cZr8OuvvwIArl+/jl27dmHIkCHt+rgoLi5GcXEx0tLSAAA7duzAwIED23XMBpGRkcjIyBBja4uY7+ukkJ6ejrCwMISEhEChUCA6OhrJycmODqvZkpOTMWvWLADArFmzsHv3bgdHZCohIQFnz57FqlWrxHntOWZfX194e3sDANzc3PCHP/wBZ8+excGDBzFlyhQA7SvmpUuXIigoCKGhoYiOjsaBAwfwpz/9qd3GCwAeHh7o1KmT+Hjs2LHIy8tr18dFaWkpioqK0LNnTwDA6NGjcebMmXYds8G0adPEqiOg7X5/Dm8oseUUGRkpnD9/XigoKBCWLl3q8HgsTVu2bBF+/fVXoa6uTigqKhLmzJkjPPDAA8KPP/4oXLhwQfjhhx+ELl26ODxOwzRs2DBBEAQhOztbyMzMFDIzM4XIyMh2HXO/fv2EjIwMITs7W8jNzRXeffddAYAQGhoqnDx5UsjPzxe2b98uuLi4ODzWhtOTTz4pNjS353hDQ0OFrKwsISsrS8jLyxN/c+35uAAg9O/fX0hPTxeys7OFXbt2CT4+Pu0+Zg8PD6G8vFzo3LmzOK8tYmY3F0REJLqvq4+IiKhlmBSIiEjEpEBERCImBSIiEjEpEBGRiEmBqAkajcakN8q27Gk3ODjYpFdcovZA7ugAiNqzmpoahIeHOzoMIrthSYGoFQoLC7Fy5Urk5OTg5MmT6NGjBwD92X9qaiqys7Px448/it2sdOvWDTt37kRWVhaysrLw+OOPAwBkMhm++uor5OXl4d///jfc3Nwctk9EBg6/M48Tp/Y6aTQa8Y7tzMxMYerUqQKg7x7acLfuiy++KN5tnJycLMycOVMAIMyePVvYtWuXAEDYtm2b8PrrrwuAvv/7zp07C8HBwYJarRb69+8vAPpxEmbMmOHwfebk9JPDA+DEqd1OlZWVZucXFhYKoaGhAqAfsKe8vFwA9GMdyOVycf7169cFAEJZWVmj7iiCg4OFCxcuiM+XLFkivPPOOw7fZ07OPbH6iKiVjLslbm23yiqVSnys1Wohl7OZjxyLSYGolV544QXx7/HjxwEAx44dQ3R0NABgxowZOHLkCAAgNTUV8+fPB6Af6Kdz584OiJjIOp6WEDXB3d0dmZmZ4vP9+/fj7bffBqAfjD47OxsqlQrTpk0DALz22mvYsGED3nzzTVy/fh2zZ88GALz++uv46quvMHfuXGi1WsyfPx9Xr161/w4RWcFeUolaobCwEIMHD8aNGzccHQpRm2L1ERERiVhSICIiEUsKREQkYlIgIiIRkwIREYmYFIiISMSkQEREov8PT18BQOp9yDwAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Double-click to view the complete implementation.\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.08\n",
        "epochs = 70\n",
        "batch_size = 100\n",
        "\n",
        "# Split the original training set into a reduced training set and a\n",
        "# validation set. \n",
        "validation_split=0.1\n",
        "\n",
        "# Identify the feature and the label.\n",
        "my_feature=\"median_income\"  # the median income on a specific city block.\n",
        "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based \n",
        "# solely on the neighborhood's median income.  \n",
        "\n",
        "# Discard any pre-existing version of the model.\n",
        "my_model = None\n",
        "\n",
        "# Shuffle the examples.\n",
        "shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index)) \n",
        "\n",
        "# Invoke the functions to build and train the model. Train on the shuffled\n",
        "# training set.\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n",
        "                                    my_label, epochs, batch_size, \n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tKN239_miW8C"
      },
      "source": [
        "Experiment with `validation_split` to answer the following questions:\n",
        "\n",
        "* With the training set shuffled, is the final loss for the training set closer to the final loss for the validation set?  \n",
        "* At what range of values of `validation_split` do the final loss values for the training set and validation set diverge meaningfully?  Why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "-UAJ3Q86iz31"
      },
      "outputs": [],
      "source": [
        "#@title Double-click for the answers to the questions\n",
        "\n",
        "# Yes, after shuffling the original training set, \n",
        "# the final loss for the training set and the \n",
        "# validation set become much closer.\n",
        "\n",
        "# If validation_split < 0.15,\n",
        "# the final loss values for the training set and\n",
        "# validation set diverge meaningfully.  Apparently,\n",
        "# the validation set no longer contains enough examples. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1PP-O8TOZOeo"
      },
      "source": [
        "## Task 4: Use the Test Dataset to Evaluate Your Model's Performance\n",
        "\n",
        "The test set usually acts as the ultimate judge of a model's quality. The test set can serve as an impartial judge because its examples haven't been used in training the model. Run the following code cell to evaluate the model with the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nd_Sw2cygOip"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 0s 3ms/step - loss: 7009.1118 - root_mean_squared_error: 83.7204\n"
          ]
        }
      ],
      "source": [
        "x_test = test_df[my_feature]\n",
        "y_test = test_df[my_label]\n",
        "\n",
        "results = my_model.evaluate(x_test, y_test, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qoyQKvsjmV_A"
      },
      "source": [
        "Compare the root mean squared error of the model when evaluated on each of the three datasets:\n",
        "\n",
        "* training set: look for `root_mean_squared_error` in the final training epoch.\n",
        "* validation set: look for `val_root_mean_squared_error` in the final training epoch.\n",
        "* test set: run the preceding code cell and examine the `root_mean_squred_error`.\n",
        "\n",
        "Ideally, the root mean squared error of all three sets should be similar. Are they?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "FxXtp-aVdIgJ"
      },
      "outputs": [],
      "source": [
        "#@title Double-click for an answer\n",
        "\n",
        "# In our experiments, yes, the rmse values \n",
        "# were similar enough. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Validation and Test Sets.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
